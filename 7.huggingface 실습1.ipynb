{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAJSCIfGVe6P"
   },
   "source": [
    "# ëª¨ë¸ & í† í¬ë‚˜ì´ì € ë¡œë”© ê¸°ë³¸ê¸° ë° ì‹¤ìŠµ ê°€ì´ë“œ\n",
    "\n",
    "- ë³¸ ìë£ŒëŠ” êµ¬ê¸€ ì½”ë©(Colab) í™˜ê²½ì—ì„œ Hugging Face `transformers` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í™œìš©í•´ ì „í•™ìŠµ(Pre-trained) ëª¨ë¸ì„ ë¡œë“œí•˜ê³ , í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•œ í† í°í™”, ëª¨ë¸ Forward Pass, ì„ë² ë”© ì¶”ì¶œ, ì„ë² ë”© ìœ ì‚¬ë„ ê³„ì‚° ë“±ì„ ì‹¤ìŠµí•´ë³´ëŠ” ì˜ˆì œë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iy-k3ZOZQqQ7"
   },
   "source": [
    "## ì‹¤ìŠµ ëª©í‘œ\n",
    "1. **Pre-trained Model ë¡œë“œ**: Hugging Faceì˜ `from_pretrained()` ë©”ì„œë“œë¥¼ í†µí•´ BERT ë˜ëŠ” DistilBERT ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•˜ëŠ” ë°©ë²•ì„ ë°°ìš´ë‹¤.\n",
    "2. **í† í¬ë‚˜ì´ì € ë¡œë”© ë° í† í°í™” ê¸°ë³¸ ì‹¤ìŠµ**: í•œê¸€ ë¬¸ì¥ì„ ì…ë ¥ìœ¼ë¡œ í•˜ì—¬ í† í°í™” ê³¼ì •ì„ ì‚´í´ë³´ê³ , token IDsë¥¼ í™•ì¸í•œë‹¤.\n",
    "3. **Forward Pass ì‹¤ìŠµ**: í† í°í™”ëœ ì…ë ¥ì„ ëª¨ë¸ì— ë„£ì–´ì„œ ì¶œë ¥(Logits, Hidden States)ì„ ë°›ì•„ë³´ê³ , ì¶œë ¥ êµ¬ì¡°ë¥¼ ì´í•´í•œë‹¤.\n",
    "4. **ë‹¤ì–‘í•œ ëª¨ë¸ ë¡œë“œ ë¹„êµ**: BERT, DistilBERT, GPT-2 ë“± ë‹¤ì–‘í•œ ëª¨ë¸ì„ ë¡œë“œí•´ë³´ê³ , ê°ê°ì˜ ì¶œë ¥ í˜•íƒœ ì°¨ì´ë¥¼ ì‚´í´ë³¸ë‹¤.\n",
    "5. **ë¬¸ì¥ ì„ë² ë”© ì¶”ì¶œ ì‹¤ìŠµ**: BERT ê¸°ë°˜ ëª¨ë¸ì˜ [CLS] í† í° ì„ë² ë”©ì„ sentence-level ì„ë² ë”©ìœ¼ë¡œ í™œìš©í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ê³ , ë¬¸ì¥ ê°„ ìœ ì‚¬ë„ë¥¼ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ ê³„ì‚°í•˜ëŠ” ê°„ë‹¨í•œ ì‹¤ìŠµì„ ì§„í–‰í•œë‹¤.\n",
    "6. **ê²½ëŸ‰ ëª¨ë¸ ë¹„êµ**: DistilBERT ë“±ì˜ ê²½ëŸ‰ ëª¨ë¸ì„ ì‚¬ìš©í–ˆì„ ë•Œì˜ ì°¨ì´ì ë„ ì‚´í´ë³¸ë‹¤.\n",
    "\n",
    "\n",
    "\n",
    "## ì‹¤ìŠµ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JT7PBHm9QlL7"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install sentencepiece  # ì¼ë¶€ í† í¬ë‚˜ì´ì €ë¥¼ ìœ„í•´ í•„ìš”í•  ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwlCCFOrSLDv"
   },
   "source": [
    "### 1. Pre-trained Model ë¡œë”©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdOYK7ZoQ98Q"
   },
   "source": [
    "**BERT ëª¨ë¸ & í† í¬ë‚˜ì´ì € ë¡œë”©**\n",
    "\n",
    "- transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ from_pretrained() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ë©´ ë§¤ìš° ê°„ë‹¨íˆ ì‚¬ì „í•™ìŠµ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•  ìˆ˜ ìˆë‹¤.\n",
    "- ì—¬ê¸°ì„œëŠ” \"bert-base-multilingual-cased\" ëª¨ë¸ì„ ì˜ˆë¡œ ë“ ë‹¤. ì´ ëª¨ë¸ì€ í•œêµ­ì–´ë¥¼ ë¹„ë¡¯í•œ ë‹¤ì–‘í•œ ì–¸ì–´ë¥¼ ì§€ì›í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287,
     "referenced_widgets": [
      "a3e7879c82614d1ea02754fa4ae3b1af",
      "7e7aef711eb842229bea0d8375751c9b",
      "efdb5ad903eb4323805de4427f7e7701",
      "c840ecf6a0be448ba67ceca38342c8fb",
      "ed528adfe8764fc5b586f7799745fb32",
      "2f8c6ec6658e4a808241967ad2bd7d3a",
      "6f483e106e9e452b9658c43d430c18e0",
      "116e239b5e5840a78f09588687e25cde",
      "2e7165d5663d49aa8af715be3aceace4",
      "cabcaa5815224d3aaf6f305aaaca37da",
      "f94f04de47c24f0b988ae91da1b9266d",
      "c34394833a674c45b9dc19c325e65350",
      "fd930b68fac6454d9f2de1238458d179",
      "74d197c039144b50846efbaf0e03cf98",
      "a74909298f1a42e9a3ca824074d267c8",
      "cc36ff9e261546a99daf02024be69a59",
      "b4e2c5b1cd254b30b9ba7cb7a1724a7e",
      "7db13a19b2164ccf9a0141130c311052",
      "1373dbb08145436680e21fb5897251e4",
      "660b6466a1804d68a7049dc72fe4c101",
      "82f035759f3c419b95596d334af56565",
      "a0da9c3821cb4bd69276c31b906c1e70",
      "be43b24f7ed14719bddb08aaf9f06a80",
      "9524e4937c40422a8fcdbf354e5e5cd1",
      "7f11b39df1ec4322b4bc3e53e2daac4a",
      "ba1d749d828f4316b6382f950d0006b7",
      "ddc35da7ab5f437c889991294b5b6090",
      "e44abff612ff4d3a939231e805b2571d",
      "e025b942c81d4ebc81dc0f920218be55",
      "db64ec12da0f4bb89ff5a7b9da0278d7",
      "740109c3c2694a2994910a905b26f1ca",
      "c246aca6952244b88152a6d79a56a557",
      "c37754e0dbc040f5adf63546196096f0",
      "53e034b9913546688ebd0093785f2c9c",
      "2b952a6fad3b450e8d630cf44b16bc25",
      "25a57d185d2148cb9dd19d63a5c7962b",
      "422b1bf5deaf45468c60f68026746583",
      "b79a510df52349c9985601fa74f53537",
      "9d54a4ca3f564a8792b0fec020bfbca2",
      "76430d6947f54d7e82edb96675c2d75d",
      "26e3125b493a4822a33bfccab9256d64",
      "29bdb9ad5f184f0780ad9815f187a00f",
      "f9899562c12446a884722e4af77d92bf",
      "e9e098ea8f2e4e3ea38c10cbe1768c5f",
      "728b874d4a144b6bb47692e989c944a0",
      "84468702c72249cca6af585af144c080",
      "9d001e891b9c40328cecdce367976b52",
      "35d9a3c12a944bb8a017499b17c0adca",
      "7a54ef1da720492691a23e686dfcdba7",
      "0f85f0db8c8f4cb0b84f750a9bc440c7",
      "6b7869203ac44d6a8245d5a8c0a14207",
      "c822db9ffa3a4c858182ad5e80658def",
      "8d07ce2acb184943abbcfba1eb020afe",
      "125f9936f33e4366b0e7e2dd9cd7db41",
      "f9c465dff4f74efcb1cae89a4c4da3ec"
     ]
    },
    "executionInfo": {
     "elapsed": 40602,
     "status": "ok",
     "timestamp": 1734249235607,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "7-wvFV_eQpZj",
    "outputId": "31e730cb-23b6-4a64-fedb-7dc3bab16445"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e7879c82614d1ea02754fa4ae3b1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34394833a674c45b9dc19c325e65350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be43b24f7ed14719bddb08aaf9f06a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e034b9913546688ebd0093785f2c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728b874d4a144b6bb47692e989c944a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# BERT ë‹¤êµ­ì–´ ëª¨ë¸ ë¡œë“œ(https://huggingface.co/google-bert/bert-base-multilingual-cased)\n",
    "model_name = \"bert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwsuD9nTQo0S"
   },
   "source": [
    "### 2. í† í¬ë‚˜ì´ì € ë¡œë”© ë° í† í°í™” ê¸°ë³¸ ì‹¤ìŠµ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uo0_oFxrTkx8"
   },
   "source": [
    "í•œê¸€ ë¬¸ì¥ì„ í† í°í™”í•´ë³´ê³ , input_idsë¥¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1734249235607,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "u0G3Je2nTmXM",
    "outputId": "5f86e9fe-1a6a-4a75-fd14-1c86e8ca001d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encodings: {'input_ids': tensor([[   101,   9521, 118741,  35506,  24982,  48549,    117,   9580, 118762,\n",
      "           8985,  49212,  11287,   9735,   9685,  77884,  48549,    119,    102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Input IDs: tensor([[   101,   9521, 118741,  35506,  24982,  48549,    117,   9580, 118762,\n",
      "           8985,  49212,  11287,   9735,   9685,  77884,  48549,    119,    102]])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "sentence = \"ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì°¸ ì¢‹ë„¤ìš”.\"\n",
    "encodings = tokenizer(sentence, return_tensors=\"pt\")\n",
    "print(\"Encodings:\", encodings)\n",
    "print(\"Input IDs:\", encodings[\"input_ids\"])\n",
    "print(\"Attention Mask:\", encodings[\"attention_mask\"])\n",
    "# token_type_idsëŠ” BERT êµ¬ì¡°ìƒ ë¬¸ì¥ìŒ ì…ë ¥ ì‹œ ì‚¬ìš©ë¨. ë‹¨ì¼ ë¬¸ì¥ì¼ ê²½ìš° ì „ë¶€ 0ì´ê±°ë‚˜ ìƒëµë  ìˆ˜ ìˆìŒ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9-wLPVZTttb"
   },
   "source": [
    "ìœ„ ì¶œë ¥ ê²°ê³¼ë¥¼ í†µí•´ í† í°í™”ëœ ê²°ê³¼(í† í° ID), attention mask ë“±ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "í† í° ì•„ì´ë””ë¥¼ ì‹¤ì œ í† í° ë¬¸ìì—´ë¡œ ë‹¤ì‹œ ë§¤í•‘í•´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì´ í•  ìˆ˜ ìˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1734249235607,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "lCgmIpNHTvgk",
    "outputId": "ef5224db-5342-479f-d869-986f0f8d69d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['[CLS]', 'ì•ˆ', '##ë…•', '##í•˜', '##ì„¸', '##ìš”', ',', 'ì˜¤', '##ëŠ˜', 'ë‚ ', '##ì”¨', '##ê°€', 'ì°¸', 'ì¢‹', '##ë„¤', '##ìš”', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(encodings[\"input_ids\"][0])\n",
    "print(\"Tokens:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y99AGgo1v3FO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFzgE1_9QoyA"
   },
   "source": [
    "### 3. ëª¨ë¸ Forward Pass ì‹¤ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 528,
     "status": "ok",
     "timestamp": 1734249370336,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "IEEFtOv_T18x",
    "outputId": "cdc81c7c-6b08-4a67-829c-dd486571dd1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last hidden state shape: torch.Size([1, 18, 768])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**encodings)\n",
    "\n",
    "# outputsì€ Base BERT ëª¨ë¸ì¼ ê²½ìš°, ì¼ë°˜ì ìœ¼ë¡œ\n",
    "# last_hidden_stateì™€ pooler_output(ì¼ë¶€ ëª¨ë¸ë§Œ), hidden_states, attentions ë“±ì„ í¬í•¨í•  ìˆ˜ ìˆë‹¤.\n",
    "# ì—¬ê¸°ì„œ outputs.last_hidden_stateëŠ” [batch_size, sequence_length, hidden_size] í˜•íƒœì˜ í…ì„œ.\n",
    "print(\"Last hidden state shape:\", outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZL8HucwUl2e"
   },
   "source": [
    "- last_hidden_state: ê° í† í°ë³„ ì„ë² ë”©(ë§ˆì§€ë§‰ ë ˆì´ì–´ ê¸°ì¤€)\n",
    "- pooler_output (BERTì˜ ê²½ìš°): [CLS] í† í°ì— ëŒ€í•œ ì„ë² ë”©ì„ ì¶”ê°€ë¡œ ë³€í™˜í•œ ë²¡í„° (sentence-level representationì„ ì œê³µí•˜ê¸° ìœ„í•´ ì‚¬ìš©)\n",
    "- [CLS] í† í°ì€ ë‹¨ìˆœí•œ ì‹œì‘ í† í°ì„ ë„˜ì–´ ë¬¸ì¥ ì „ì²´ì˜ ì •ë³´ë¥¼ ìš”ì•½í•˜ë„ë¡ í•™ìŠµë˜ëŠ” ê²½í–¥ì´ ìˆìŒ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 270,
     "status": "ok",
     "timestamp": 1734250145657,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "TSLG7sxGUh7R",
    "outputId": "c2781586-6a9e-4701-aaba-315b044b3e8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooler output shape: torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "if hasattr(outputs, 'pooler_output'):\n",
    "    print(\"Pooler output shape:\", outputs.pooler_output.shape)\n",
    "else:\n",
    "    # ë‹¨, AutoModelë¡œ ë¡œë“œí•œ Base BERTëŠ” pooler_outputì„ í¬í•¨í•˜ë©°,\n",
    "    # AutoModelForMaskedLM ë“±ì˜ ë‹¤ë¥¸ í—¤ë“œ ëª¨ë¸ì€ êµ¬ì¡°ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ.\n",
    "    print(\"ì´ ëª¨ë¸ì€ pooler_outputì„ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwD83MPMSXml"
   },
   "source": [
    "### 4. ë‹¤ì–‘í•œ ëª¨ë¸ ë¡œë“œí•´ë³´ê¸° (DistilBERT, GPT-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btgne6ssU3rU"
   },
   "source": [
    "DistilBERT ë¡œë“œ\n",
    "DistilBERTëŠ” BERTë³´ë‹¤ íŒŒë¼ë¯¸í„° ìˆ˜ê°€ ì ê³  ë¹ ë¥¸ ì¶”ë¡ ì´ ê°€ëŠ¥í•˜ë©°, ì„±ëŠ¥ì€ ë¹„êµì  ë¹„ìŠ·í•œ ê²½ëŸ‰ ëª¨ë¸ì´ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2190,
     "status": "ok",
     "timestamp": 1734250340754,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "ZQ8rXIJDU3WD",
    "outputId": "c194ba72-a69d-48e9-a180-59597c94ff0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT last_hidden_state shape: torch.Size([1, 18, 768])\n",
      "ì´ ëª¨ë¸ì€ pooler_outputì„ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "distil_name = \"distilbert-base-multilingual-cased\"\n",
    "distil_tokenizer = AutoTokenizer.from_pretrained(distil_name)\n",
    "distil_model = AutoModel.from_pretrained(distil_name)\n",
    "\n",
    "distil_encodings = distil_tokenizer(sentence, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    distil_outputs = distil_model(**distil_encodings)\n",
    "\n",
    "print(\"DistilBERT last_hidden_state shape:\", distil_outputs.last_hidden_state.shape)\n",
    "\n",
    "# DistilBERTëŠ” pooler_outputì´ ì—†ëŠ” ê²½ìš°ê°€ ë§ë‹¤.\n",
    "if hasattr(distil_outputs, 'pooler_output'):\n",
    "    print(\"Pooler output shape:\", distil_outputs.pooler_output.shape)\n",
    "else:\n",
    "    print(\"ì´ ëª¨ë¸ì€ pooler_outputì„ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GICaXC7bU6GM"
   },
   "source": [
    "GPT-2 ë¡œë“œ\n",
    "- GPT-2ëŠ” Decoder ê¸°ë°˜ ì–¸ì–´ ëª¨ë¸ë¡œ, causal language modeling ëª©ì ìœ¼ë¡œ ì‚¬ì „í•™ìŠµë˜ì—ˆë‹¤.\n",
    "- í•œêµ­ì–´ ì§€ì› ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ë„ ìˆìœ¼ë‚˜ ì—¬ê¸°ì„œëŠ” ê¸°ë³¸ gpt2 ì˜ë¬¸ ëª¨ë¸ì„ ì˜ˆë¡œ ë“¤ì–´ ì¶œë ¥ êµ¬ì¡° ì°¨ì´ë¥¼ ì‚´í´ë³¸ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227,
     "referenced_widgets": [
      "ed49bf60018349a393ba78d1235a4d57",
      "d44ebdf716984d21bdbd2ab86c3bf5c7",
      "c2b1e4126fe14912b2b4b18f45db6c5e",
      "f1dd57d1be724b50b2d0c810d3b0eaee",
      "aa0c455290d64ad0aea1650f36288e97",
      "3870224b110a4bc59d259d356949a774",
      "377c2fd1fba044aa909dfa9bbe7fc5f7",
      "65578f7c450c4e54ae9317ac2232b0cd",
      "ff4e84ce5cc245a998d34d81722436b3",
      "af56617bb97140fea81c925427a15ef4",
      "47d2b9f2533d4e29a5f0af6d90e4a051",
      "b9cd457dae8a4eceaa227c812851e13f",
      "68906017bc874dd28f954dbf96b79143",
      "b170210fbbd44fb4a731cd40663a2d05",
      "6276b5e8258040288a6cdac2305ca1de",
      "03f5f1dfa34e4318b7263ffdbe3d3429",
      "c8c9330a8e5049cc8ad6ce596b410d85",
      "033b8d5e3993481fa89e205e3c6b7995",
      "532afedf012848909ceb7aef8ac3c22a",
      "7ad3ed1fdf564496b661195414e0e1d4",
      "cc7354dc00644959a45f43a9a726f01d",
      "43f69c0171c1480dbad1545aea416dec",
      "97aed02011504eb583f3ae3b1a34ee42",
      "af8479c0c2cf4497b9e66b759b3237f7",
      "2cd2bc38746d403d9f090e409c6d4128",
      "e88c68be14f04c6ab55dc32d618e3120",
      "1a1a2ee3c7564cc4883d98ee726a8c5c",
      "ad376ecd4e274fedb9da5bb8a9a354e8",
      "dc010c4a9b6f48fc9649c31ce4e25039",
      "c441336e2d334fa5b194493fde321b19",
      "f1a27c80e4484a139646d579a6532b71",
      "da07b5239cb641568564fdc098157356",
      "8ec5f081ec694908876bfc5b3c806d95",
      "9264609eee9149a2b54dbe2e083a0243",
      "ca60fab8220245f3ab8c5fe54f7a0bf5",
      "69459449f9be4cd490abc154fe565f38",
      "30d4acde7fd74c16b5b34ebe4ba2c955",
      "65a83430a01f4b1e832a9ca3d85d378e",
      "8b219195f35044489e9b162a01ade4cc",
      "f382e123a8b64cf09ae937273f0776c3",
      "8d3be14e19294b84bb6da75799e7d419",
      "d55225c8901c40cba25dd153f992e0e0",
      "ad47db1094cc4044bb5a3ad44afe63d3",
      "6bcf84d763da4cc6b76a83c634cb958f",
      "0e3890cfd819467680df31917858a26f",
      "ca6b8a793d6e4bd98c47a459f5b9320d",
      "9d64d3876c964827b83ba7064705c9d0",
      "cb879f2b24af41e0bcc0a681e87c33e5",
      "3a7289e583514ba39d84bbfd04839d18",
      "604f3ea1c8c3426f9902541469d9463c",
      "4ae699d9c0c843779a2f6b46f87e2a34",
      "82159bd9a3524de2b5376ae5f5d85e33",
      "53ad5cdc8f574168bbfcfd3511c521f6",
      "e0748ba8b8a8445f9c44c9930a4a02fe",
      "30e1f3acc81246f8913a00ca14c8c5b1",
      "cb05da32895a486f84647f1f79e44714",
      "fd849e4d26544108b90973bfedbb3fd3",
      "c87bfe7129c740a08f1c2bcd0b532cc7",
      "76c0c8ff869c47579aae60fc26ba782e",
      "4bbf2c24360f4821995025d80d7e49d4",
      "0616a3ae8d234983b017376f327b6597",
      "3a88007bda8a4e67b81df4a0a64f6b75",
      "fd4495ecbf384abe94bcb81606a1d367",
      "3654972832de4d029483ce64fe596791",
      "b59d38f7cb1e4667b7f164fcacfce04e",
      "40b47c378a724095ab0eac4524ebfa1d"
     ]
    },
    "executionInfo": {
     "elapsed": 10709,
     "status": "ok",
     "timestamp": 1734249647177,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "OXuaw1u2U7EO",
    "outputId": "96ce89f6-62ab-4649-e02e-bc8970ac65ba"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed49bf60018349a393ba78d1235a4d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9cd457dae8a4eceaa227c812851e13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97aed02011504eb583f3ae3b1a34ee42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9264609eee9149a2b54dbe2e083a0243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3890cfd819467680df31917858a26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb05da32895a486f84647f1f79e44714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 last_hidden_state shape: torch.Size([1, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "gpt2_name = \"gpt2\"\n",
    "gpt2_tokenizer = AutoTokenizer.from_pretrained(gpt2_name)\n",
    "gpt2_model = AutoModel.from_pretrained(gpt2_name)\n",
    "\n",
    "gpt2_encodings = gpt2_tokenizer(\"Hello world!\", return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    gpt2_outputs = gpt2_model(**gpt2_encodings)\n",
    "\n",
    "print(\"GPT-2 last_hidden_state shape:\", gpt2_outputs.last_hidden_state.shape)\n",
    "# GPT-2ëŠ” [batch_size, sequence_length, hidden_size] í˜•íƒœì˜ last_hidden_stateë¥¼ ë°˜í™˜í•˜ë©°,\n",
    "# pooler_outputì´ë‚˜ CLS í† í° ê°œë…ì´ ì—†ìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNdGa1ZBU-LZ"
   },
   "source": [
    "ì´ì²˜ëŸ¼ ëª¨ë¸ë³„ë¡œ ì¶œë ¥ í˜•íƒœì™€ í™œìš© ë°©ì‹ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2blpoYl2SaYy"
   },
   "source": [
    "### 5. ë¬¸ì¥ ì„ë² ë”© ì¶”ì¶œ ì‹¤ìŠµ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1JZTEc-VAKT"
   },
   "source": [
    "BERT ê¸°ë°˜ ëª¨ë¸ì—ì„œ ë¬¸ì¥ ì„ë² ë”©ì„ ì–»ëŠ” í•œ ê°€ì§€ ë°©ë²•ì€ [CLS] í† í° ì„ë² ë”©ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë‹¤. [CLS] í† í°ì€ ë¬¸ì¥ ì „ì²´ë¥¼ ëŒ€í‘œí•˜ëŠ” í† í°ìœ¼ë¡œ ê°„ì£¼ë˜ë©°, BERTëŠ” ì´ë¥¼ í†µí•´ ë¬¸ì¥ ë‹¨ìœ„ íƒœìŠ¤í¬ë¥¼ ìˆ˜í–‰í•˜ë„ë¡ í•™ìŠµë˜ì—ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1734249647177,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "KBsv9QzLVBd0",
    "outputId": "ea9ed6d4-4eb5-4b0e-a0a8-4c81d8594b69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLS embedding shape: torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    bert_outputs = model(**encodings)\n",
    "# bert_outputs.last_hidden_state: [batch_size, seq_length, hidden_size]\n",
    "# ì²« ë²ˆì§¸ í† í° [CLS] ì„ë² ë”©ì„ ì¶”ì¶œ\n",
    "cls_embedding = bert_outputs.last_hidden_state[:, 0, :]  # [batch_size, hidden_size]\n",
    "print(\"CLS embedding shape:\", cls_embedding.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1734250755944,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "1fx-RG6LZXYd",
    "outputId": "014e34d6-fa2f-4ae2-b3a0-31fb8763f635"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1557,  0.0021,  0.2183,  0.0628,  0.1071,  0.4759,  0.0425,  0.2050,\n",
       "         -0.3615,  0.3048]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_outputs.pooler_output[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1734250763656,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "rLQ0_6njZVNE",
    "outputId": "dca691e3-5cf1-4b50-e421-8b21c2c4556e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1557,  0.0021,  0.2183,  0.0628,  0.1071,  0.4759,  0.0425,  0.2050,\n",
       "         -0.3615,  0.3048]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.pooler_output[:,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwOcDSuQVDk_"
   },
   "source": [
    "cls_embeddingëŠ” í•´ë‹¹ ë¬¸ì¥ì„ ëŒ€í‘œí•˜ëŠ” ì„ë² ë”©ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tkSjvgnSc_9"
   },
   "source": [
    "### 6. DistilBERT ë“± ê²½ëŸ‰ ëª¨ë¸ê³¼ì˜ ë¹„êµ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yc1FuDT4VGal"
   },
   "source": [
    "DistilBERTë„ ë¬¸ì¥ ì„ë² ë”©ìš©ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•˜ë‚˜, poolerë‚˜ [CLS] í† í° í™œìš© ë°©ì‹ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë³´í†µ ë§ˆì§€ë§‰ íˆë“  ìŠ¤í…Œì´íŠ¸ì˜ í‰ê· (Mean Pooling) ë“±ì„ í†µí•´ ë¬¸ì¥ ì„ë² ë”©ì„ ì–»ëŠ”ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1734249647593,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "tC_1Ai3DVC8N",
    "outputId": "b4d6cec6-e560-4aeb-e880-4429df8f226f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT CLS embedding shape: torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    distil_outputs = distil_model(**distil_encodings)\n",
    "\n",
    "# DistilBERTì—ëŠ” CLS í† í°ì´ ì²« í† í°ì— í•´ë‹¹í•˜ë‚˜ pooler_outputì´ ì—†ìœ¼ë¯€ë¡œ ë§ˆì§€ë§‰ íˆë“  ìŠ¤í…Œì´íŠ¸ ì²« í† í°ì„ ì‚¬ìš©í•˜ê±°ë‚˜,\n",
    "# í˜¹ì€ mean poolingì„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.\n",
    "distil_cls_embedding = distil_outputs.last_hidden_state[:, 0, :]\n",
    "print(\"DistilBERT CLS embedding shape:\", distil_cls_embedding.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uU2J3XvSc93"
   },
   "source": [
    "### 7. ì„ë² ë”© ê°„ ìœ ì‚¬ë„ ê³„ì‚° (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTHEMwW6VJFz"
   },
   "source": [
    "ë¬¸ì¥ ì„ë² ë”©ì„ ì–»ì—ˆìœ¼ë‹ˆ, ë‘ ë¬¸ì¥ ê°„ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•´ë³´ì. ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ì‚¬ìš©í•˜ë©´ ì‰½ê²Œ ë¹„êµ ê°€ëŠ¥í•˜ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1734249647593,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "ZFTey6vDVKKJ",
    "outputId": "bae75e0d-14e1-42fd-8aee-7c5a39e93092"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.9361767768859863\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sentences = [\"ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”.\", \"ì •ë§ ë§‘ê³  í™”ì°½í•œ ë‚ ì”¨ë„¤ìš”.\"]\n",
    "encodings_1 = tokenizer(sentences[0], return_tensors=\"pt\")\n",
    "encodings_2 = tokenizer(sentences[1], return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    out1 = model(**encodings_1)\n",
    "    out2 = model(**encodings_2)\n",
    "\n",
    "cls_embed_1 = out1.last_hidden_state[:,0,:]\n",
    "cls_embed_2 = out2.last_hidden_state[:,0,:]\n",
    "\n",
    "# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "cos_sim = F.cosine_similarity(cls_embed_1, cls_embed_2)\n",
    "print(\"Cosine similarity:\", cos_sim.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89GEXSw7VMIY"
   },
   "source": [
    "- ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê°’ì´ 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë§¤ìš° ìœ ì‚¬í•œ ì˜ë¯¸ì˜ ë¬¸ì¥, -1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë§¤ìš° ë‹¤ë¥¸ ì˜ë¯¸ì˜ ë¬¸ì¥ì„ì„ ë‚˜íƒ€ë‚¸ë‹¤.\n",
    "\n",
    "- ìœ ì‚¬í•œ ë¬¸ì¥ (\"ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì¢‹ë„¤ìš”.\" vs \"ì •ë§ ë§‘ê³  í™”ì°½í•œ ë‚ ì”¨ë„¤ìš”.\")ì˜ ê²½ìš° ë†’ì€ ìœ ì‚¬ë„(0.8 ì´ìƒ)ê°€ ë‚˜ì˜¬ ê²ƒìœ¼ë¡œ ê¸°ëŒ€í•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZOnqRGmSkpt"
   },
   "source": [
    "### 8. ì •ë¦¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzv1KJYRSpqK"
   },
   "source": [
    "- from_pretrained() ë©”ì„œë“œë¥¼ í†µí•´ ì†ì‰½ê²Œ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•  ìˆ˜ ìˆë‹¤.\n",
    "- í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•´ ì…ë ¥ ë¬¸ì¥ì„ í† í°í™”í•˜ê³ , input_ids, attention_mask, token_type_ids ë“±ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n",
    "- ë‹¤ì–‘í•œ ëª¨ë¸(BERT, DistilBERT, GPT-2)ì„ ë¡œë“œí•˜ê³  Forward Passë¥¼ ìˆ˜í–‰í•´ë³´ë©´, ê° ëª¨ë¸ì˜ ì¶œë ¥ í˜•ì‹(íˆë“  ìŠ¤í…Œì´íŠ¸, pooler_output, etc.)ì— ëŒ€í•œ ì´í•´ë¥¼ ë„“í ìˆ˜ ìˆë‹¤.\n",
    "- BERT ê¸°ë°˜ ëª¨ë¸ì—ì„œ [CLS] í† í° ì„ë² ë”©ì„ ë¬¸ì¥ ì„ë² ë”©ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆìœ¼ë©°, ì„ë² ë”© ê°„ ìœ ì‚¬ë„(ì½”ì‚¬ì¸ ìœ ì‚¬ë„) ê³„ì‚°ì„ í†µí•´ ë¬¸ì¥ ê°„ ì˜ë¯¸ì  ìœ ì‚¬ë„ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆë‹¤.\n",
    "- DistilBERT ë“±ì˜ ê²½ëŸ‰ ëª¨ë¸ì„ ì‚¬ìš©í•´ë„ ìœ ì‚¬í•œ ê³¼ì •ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìœ¼ë©°, í•„ìš”í•œ ê²½ìš° mean pooling ë“± ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ë¬¸ì¥ ì„ë² ë”©ì„ ì–»ì„ ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6HluRVMz1oL"
   },
   "source": [
    "# BERT ëª¨ë¸ íŒŒì¸íŠœë‹ì„ í™œìš©í•œ ì±—ë´‡ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WdkDHf10S0Q"
   },
   "source": [
    "## BERTë€?\n",
    "BERT(Bidirectional Encoder Representations from Transformers)ëŠ” êµ¬ê¸€ì—ì„œ ê°œë°œí•œ ì‚¬ì „ í›ˆë ¨ëœ ìì—°ì–´ ì²˜ë¦¬ ëª¨ë¸ë¡œ, ë‹¤ì–‘í•œ ì–¸ì–´ ì´í•´ íƒœìŠ¤í¬ì—ì„œ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤. BERTì˜ í•µì‹¬ì€ íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ì˜ ì–‘ë°©í–¥ ì¸ì½”ë”ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "## í•µì‹¬ ê¸°ìˆ \n",
    "### íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸\n",
    "íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” 'ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜'ì„ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ ë°ì´í„°ì˜ ê° ìš”ì†Œ ê°„ì˜ ê´€ê³„ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤. BERTëŠ” ì´ íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ì¸ì½”ë” êµ¬ì¡°ë§Œì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì–‘ë°©í–¥ í›ˆë ¨\n",
    "BERTì˜ ë˜ ë‹¤ë¥¸ ì¤‘ìš”í•œ íŠ¹ì§•ì€ ì–‘ë°©í–¥ìœ¼ë¡œ ë¬¸ë§¥ì„ ì´í•´í•©ë‹ˆë‹¤. ì´ëŠ” ê¸°ì¡´ ë‹¨ë°©í–¥ ë˜ëŠ” ì–‘ë°©í–¥ì´ ì œí•œëœ ëª¨ë¸ë“¤ê³¼ ë¹„êµí•˜ì—¬ ë¬¸ë§¥ íŒŒì•…ì— ë”ìš± íš¨ê³¼ì ì…ë‹ˆë‹¤.\n",
    "\n",
    "## ì‚¬ì „ í›ˆë ¨ íƒœìŠ¤í¬\n",
    "BERTëŠ” ë‘ ê°€ì§€ ì£¼ìš” íƒœìŠ¤í¬ë¥¼ í†µí•´ ì‚¬ì „ í›ˆë ¨ë©ë‹ˆë‹¤.\n",
    "\n",
    "<img src=\"https://velog.velcdn.com/images/tm011899/post/72149edb-a1f0-46e0-aebe-4e89c0a490ae/image.PNG\" width=\"600\">\n",
    "\n",
    "1. **Masked Language Model (MLM)**\n",
    "   - ë¬´ì‘ìœ„ë¡œ ì„ íƒëœ í† í°ì„ ë§ˆìŠ¤í‚¹í•˜ê³ , ë§ˆìŠ¤í‚¹ëœ í† í°ì„ ì˜ˆì¸¡í•˜ë„ë¡ í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œ ëª¨ë¸ì€ ì–‘ë°©í–¥ ë¬¸ë§¥ì„ ê³ ë ¤í•´ì•¼ë§Œ ì •í™•í•œ ì˜ˆì¸¡ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
    "2. **Next Sentence Prediction (NSP)**\n",
    "   - ë‘ ê°œì˜ ë¬¸ì¥ì´ ì£¼ì–´ì¡Œì„ ë•Œ, ë‘ ë²ˆì§¸ ë¬¸ì¥ì´ ì²« ë²ˆì§¸ ë¬¸ì¥ì˜ ë‹¤ìŒ ë¬¸ì¥ì¸ì§€ ê´€ê³„ ì—†ëŠ” ë¬¸ì¥ì¸ì§€ ì˜ˆì¸¡í•©ë‹ˆë‹¤. ì´ íƒœìŠ¤í¬ëŠ” íŠ¹íˆ ë¬¸ì„œ ìˆ˜ì¤€ì˜ ì´í•´ì™€ ê´€ê³„ ì¶”ë¡ ì— ë„ì›€ì„ ì¤ë‹ˆë‹¤.\n",
    "\n",
    "## í™œìš© ì˜ˆ\n",
    "BERTëŠ” ìì—°ì–´ ì´í•´ ê´€ë ¨ ë‹¤ì–‘í•œ íƒœìŠ¤í¬ì— ì ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê°ì„± ë¶„ì„, ì§ˆë¬¸ ì‘ë‹µ ì‹œìŠ¤í…œ, ë¬¸ì¥ ë¶„ë¥˜ ë“±ì— í™œìš©ë˜ì–´ ìš°ìˆ˜í•œ ê²°ê³¼ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.\n",
    "\n",
    "## ì„±ê³¼\n",
    "BERTëŠ” ì¶œì‹œë˜ìë§ˆì ì—¬ëŸ¬ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœê³  ì„±ëŠ¥ì„ ê¸°ë¡í•˜ë©°, NLP ë¶„ì•¼ì—ì„œ ìƒˆë¡œìš´ ê¸°ì¤€ì„ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J7waf7xjquVx"
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "438a1772be1545528426306cb8747df4",
      "ef6a114ad1644dfb8439a7681434273f",
      "4f0b76ba2219407d9d9fc03954e596f4",
      "d90f586f983a4d6bbd8524a8234fd140",
      "4546df75e69c49098120f1c37e45c5d8",
      "6beb88ef9e7a4830b5b35ce2b5aba17e",
      "0557ad6648424f46b610834ddd1f59e4",
      "dfd685ba6b5d40e99eb119c60296676b",
      "079694b48f68432fb29f7409f6a13ce3",
      "70061a8017944ee5a7a42314a0cf7388",
      "ccc1f474791643d59975e3af15165fb8",
      "88333deef31345979012e1985184ebef",
      "4c7b328bd22543c6942cad9576d610d7",
      "ca0360968e0e48119a08ba503de0a583",
      "aac7d2f2833b40fb809207ea378539a1",
      "f9434331c4af4867a88157f23ffdc10a",
      "4c04ff1f506d40f894eee80261c273d7",
      "5ff55cfd2c2d4201bfcdedf874787b0d",
      "93135d19c327487395ba7a00a85af6de",
      "08f62365fab8440fb63f37fc32bbfed6",
      "0d4e18d99c2041a085e42cc22e72a1a5",
      "4950eef80eb84358ac5fc1217cfd68e2",
      "86b4c25895cc4701ad8ffca87b9111e1",
      "da3f683b0e684604b00fffe60e7ca38b",
      "4e57dcc04d72442493a44d1fd257e37b",
      "1122661ec7634269883238fd96396149",
      "94820df6212f4108abbb4c8a49f63277",
      "f68577045c0840aa85586d06c9199bc5",
      "3c1ab5b3c6e0436081c7958c204a9cf5",
      "38341915fa354238aa40c1dd756288eb",
      "314467fa6ed9436fa111af68e49887b2",
      "2425a9ccbea8415fbe1ccad2081bddc7",
      "ec3000c16d3a462abbc10ed004f324f3",
      "ae5c383d5e634164a736f3f998e3593c",
      "2498a43a3d614377af4045159ed98857",
      "9d7edf08a4ac44e8b520d767dcc68d81",
      "f4b55938d77645cf883d8ff0733d1a33",
      "13ba5377b000460698ae4867d725340e",
      "b91fcf5ac05e41acbadb98f83a205929",
      "75e69fb59be74accac0aa07b026e2050",
      "3406f3e073db49d79f3811d035e1a423",
      "ef904ee9a9e3429ca452bb1b64aeb2a3",
      "2079e1fa23b54c90a2e322083196e677",
      "498db1cbbfc04e8e94dea8a48b5b8729",
      "66d6a1cef8a14aac969d69565e97840f",
      "56a8433925a74c1aa8188b128fdfd02a",
      "0bcf299a7e5b4bbe9ad591a29081e32c",
      "6e4f39fbadaf48cb8a25558a5ae7d3e5",
      "72911ecc582141bb844f6e18574a8e1f",
      "ed639ca930cf43e59037e90bc1d1e1bc",
      "fab508ee8e6a4e22953c35c5ec60ea46",
      "84f77eac4df34b8b8468f50fe1260536",
      "96446130cac74343abed1e0fbca34b3a",
      "cb0ac3e37189497a88aceb9fea32a3e3",
      "00ab498a7d6d42af88f4a11e91911804",
      "a98f502beadf476cb336be768fd232f9",
      "7d022b0db2c34a4f9ea9ca4d7492c4c3",
      "aebb07fa7a5f47cab284638450215114",
      "d0442c286365419aa0fdc234d0003cfe",
      "16bfe224fcdc4625aeaf4a28508b5042",
      "faf0527ff9134bf1841d7bc113359790",
      "75821589bddb47039f569a1ed3fd42d0",
      "6fc7f987b6e643b0b0bbb845dabac794",
      "e050fd98817141738459ce698d965932",
      "70436209e1624d19b07185e1cd9d56d6",
      "7dc60a36eb084fd3b716d9b2a2ad192e",
      "8ed5537618734f3dbd462b09ee9a5a07",
      "b41b92cf9a72471f94234d089a981eca",
      "6d2db3be7d7d42b2bc4d9b39c30ebf80",
      "05e01aff72b1469da8b77d39ff2584a4",
      "83f22bd4dc6a4d70a269c3eebb217210",
      "5467d48c6d854620a7e6e31296e55160",
      "584462b01d784fed97051d501bf57e3a",
      "d95c3ec152944c9ebcc6f56fef500052",
      "af9049f261624fbf8b75ea47f57a0702",
      "5d052523ee18468abff495b09af78785",
      "12d18b8076a74bf891bb4ed30753d8aa"
     ]
    },
    "executionInfo": {
     "elapsed": 47390,
     "status": "ok",
     "timestamp": 1734370176578,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "sjaHTEQ9z4TA",
    "outputId": "202555ae-a178-4c96-fb8a-49b659a79645"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438a1772be1545528426306cb8747df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88333deef31345979012e1985184ebef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b4c25895cc4701ad8ffca87b9111e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae5c383d5e634164a736f3f998e3593c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d6a1cef8a14aac969d69565e97840f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.bert.modeling_bert.BertModel'> is overwritten by shared encoder config: BertConfig {\n",
      "  \"_name_or_path\": \"klue/bert-base\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.bert.modeling_bert.BertLMHeadModel'> is overwritten by shared decoder config: BertConfig {\n",
      "  \"_name_or_path\": \"klue/bert-base\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": true,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì±—ë´‡ ìƒ˜í”Œì˜ ê°œìˆ˜ : 11662\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98f502beadf476cb336be768fd232f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10495 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4114: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed5537618734f3dbd462b09ee9a5a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1167 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ë°ì´í„° ì²˜ë¦¬ ë° í•™ìŠµì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "from transformers import BertTokenizer, EncoderDecoderModel, EncoderDecoderConfig, Trainer, TrainingArguments,AutoConfig\n",
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd                 # ë°ì´í„°í”„ë ˆì„ê³¼ CSV íŒŒì¼ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import urllib.request               # URLì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import time                         # í•™ìŠµ ì‹œê°„ ì¸¡ì •ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import numpy as np                  # ìˆ˜í•™ ê³„ì‚° ë° ë°°ì—´ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import matplotlib.pyplot as plt     # ê·¸ë˜í”„ ë° ë°ì´í„° ì‹œê°í™”ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import torch\n",
    "import re                           # ì •ê·œ í‘œí˜„ì‹ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "\n",
    "# ì±—ë´‡ ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\",\n",
    "    filename=\"ChatBotData.csv\")  # URLì—ì„œ ì±—ë´‡ ë°ì´í„°ë¥¼ ë¡œì»¬ë¡œ ë‹¤ìš´ë¡œë“œ\n",
    "\n",
    "# BERT í† í¬ë‚˜ì´ì €ì™€ ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "tokenizer = BertTokenizer.from_pretrained('klue/bert-base')\n",
    "config = EncoderDecoderConfig.from_encoder_decoder_configs(\n",
    "    encoder_config=AutoConfig.from_pretrained('klue/bert-base'),\n",
    "    decoder_config=AutoConfig.from_pretrained('klue/bert-base')\n",
    ")\n",
    "# ë””ì½”ë”ì˜ ì‹œì‘ í† í° IDë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "config.decoder_start_token_id = tokenizer.cls_token_id  # CLS í† í°ì„ ì‹œì‘ í† í°ìœ¼ë¡œ ì‚¬ìš©\n",
    "# íŒ¨ë”© í† í° IDë„ ì„¤ì •í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.\n",
    "config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# ì„¤ì •ëœ êµ¬ì„±ì„ ë°”íƒ•ìœ¼ë¡œ ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "model = EncoderDecoderModel(config=config)\n",
    "\n",
    "# GPU ì‚¬ìš©ì´ ê°€ëŠ¥í•œ í™˜ê²½ì´ë¼ë©´, ëª¨ë¸ì„ GPUë¡œ ì´ë™ì‹œí‚µë‹ˆë‹¤.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# CSV íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³ , ê²°ì¸¡ì¹˜ë¥¼ í™•ì¸ ë° ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
    "df = pd.read_csv('ChatBotData.csv')\n",
    "# ì¤‘ë³µë°ì´í„° ì œê±°\n",
    "df = df.drop_duplicates(subset='Q', keep='first')\n",
    "print('ì±—ë´‡ ìƒ˜í”Œì˜ ê°œìˆ˜ :', len(df))\n",
    "\n",
    "\n",
    "# ì§ˆë¬¸ê³¼ ë‹µë³€ ë°ì´í„° ì „ì²˜ë¦¬\n",
    "questions = df['Q'].apply(lambda x: re.sub(r\"([?.!,])\", r\" \\1 \", x).strip())\n",
    "answers = df['A'].apply(lambda x: re.sub(r\"([?.!,])\", r\" \\1 \", x).strip())\n",
    "\n",
    "# í† í¬ë‚˜ì´ì§• ë° ë°ì´í„°ì…‹ ë³€í™˜\n",
    "def tokenize_function(examples):\n",
    "    model_inputs = tokenizer(examples['questions'], max_length=40, truncation=True, padding='max_length')\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples['answers'], max_length=40, truncation=True, padding='max_length')['input_ids']\n",
    "    model_inputs['labels'] = labels\n",
    "    return model_inputs\n",
    "\n",
    "# ë°ì´í„°ì…‹ì„ í›ˆë ¨ ë° ê²€ì¦ìš©ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.\n",
    "train_size = int(0.9 * len(questions))\n",
    "train_dataset = Dataset.from_dict({'questions': questions[:train_size], 'answers': answers[:train_size]})\n",
    "val_dataset = Dataset.from_dict({'questions': questions[train_size:], 'answers': answers[train_size:]})\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3932705,
     "status": "ok",
     "timestamp": 1734374109280,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "Zpfa-zcLqb7A",
    "outputId": "fd6732cf-510e-474a-c53c-35ae95406d86"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20241216_173603-38g1gxhz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/minsukim/huggingface/runs/38g1gxhz' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/minsukim/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/minsukim/huggingface' target=\"_blank\">https://wandb.ai/minsukim/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/minsukim/huggingface/runs/38g1gxhz' target=\"_blank\">https://wandb.ai/minsukim/huggingface/runs/38g1gxhz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:629: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:649: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1640' max='1640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1640/1640 58:59, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.542400</td>\n",
       "      <td>9.344317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.137200</td>\n",
       "      <td>7.869624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.226400</td>\n",
       "      <td>5.880588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.873900</td>\n",
       "      <td>3.499101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.345000</td>\n",
       "      <td>1.416778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.886800</td>\n",
       "      <td>1.033488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.803700</td>\n",
       "      <td>0.972997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.714200</td>\n",
       "      <td>0.945585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.656600</td>\n",
       "      <td>0.934352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.623800</td>\n",
       "      <td>0.922413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.599000</td>\n",
       "      <td>0.924995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.564800</td>\n",
       "      <td>0.919953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.527500</td>\n",
       "      <td>0.919659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>0.926541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.474400</td>\n",
       "      <td>0.926546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.455600</td>\n",
       "      <td>0.926907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.426700</td>\n",
       "      <td>0.932189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.418700</td>\n",
       "      <td>0.933352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.407000</td>\n",
       "      <td>0.936447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.405900</td>\n",
       "      <td>0.936567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:629: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:649: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:629: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:649: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:629: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:649: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:629: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:649: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1640, training_loss=2.0652259881903485, metrics={'train_runtime': 3930.0477, 'train_samples_per_second': 53.409, 'train_steps_per_second': 0.417, 'total_flos': 1.0059763181568e+16, 'train_loss': 2.0652259881903485, 'epoch': 20.0})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# íŠ¸ë ˆì´ë„ˆ ì„¤ì •ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=256,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\"  # ê° ì—í­ë§ˆë‹¤ ê²€ì¦ ë°ì´í„°ë¡œ í‰ê°€\n",
    ")\n",
    "\n",
    "# íŠ¸ë ˆì´ë„ˆ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "su5OFZcyxDLR"
   },
   "outputs": [],
   "source": [
    "# ì‚¬ìš©ì ì…ë ¥ì— ëŒ€í•´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "def chat(question):\n",
    "    inputs = tokenizer(question, return_tensors='pt', max_length=40, truncation=True, padding=\"max_length\")\n",
    "    inputs.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(inputs['input_ids'])\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 928,
     "status": "ok",
     "timestamp": 1734374979353,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "CvhQEWlLxD9a",
    "outputId": "ff5f26e9-426a-4eca-b9a3-d98b72100a70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜í•  ìˆ˜ ìˆì„ ê±°ì˜ˆìš”.\n"
     ]
    }
   ],
   "source": [
    "# ì±—ë´‡ í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ\n",
    "print(chat(\"ê³ ë¯¼ì´ ìˆì–´\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 956,
     "status": "ok",
     "timestamp": 1734374893393,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "Uyss1pahfLw6",
    "outputId": "9bf19911-e6ae-4118-9398-a1c7dd472e0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜í•  ìˆ˜ ìˆì„ ê±°ì˜ˆìš”.\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"ë¯¸ë˜ëŠ” ì–´ë–¨ê¹Œ?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 944,
     "status": "ok",
     "timestamp": 1734374936116,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "q4g5YWZlzKE0",
    "outputId": "0cf55d34-4eae-481f-8d39-9050422dc81d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¢‹ì€ ê³³ìœ¼ë¡œ ê°€ë³´ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"ì¹´í˜ê°ˆë˜?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 450,
     "status": "ok",
     "timestamp": 1734374961553,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "YwVCNtVjzW49",
    "outputId": "88ad1a31-0e84-4f81-d63b-00cd7d71a44f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìì‹ ì„ ë” ì‚¬ë‘í•´ì£¼ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"ë„ˆë¬´ í™”ê°€ë‚˜\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOI33mZeiLPNSWmuoVzb2gG",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
