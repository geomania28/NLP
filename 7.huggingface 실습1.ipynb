{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAJSCIfGVe6P"
   },
   "source": [
    "# 모델 & 토크나이저 로딩 기본기 및 실습 가이드\n",
    "\n",
    "- 본 자료는 구글 코랩(Colab) 환경에서 Hugging Face `transformers` 라이브러리를 활용해 전학습(Pre-trained) 모델을 로드하고, 토크나이저를 사용한 토큰화, 모델 Forward Pass, 임베딩 추출, 임베딩 유사도 계산 등을 실습해보는 예제를 포함하고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iy-k3ZOZQqQ7"
   },
   "source": [
    "## 실습 목표\n",
    "1. **Pre-trained Model 로드**: Hugging Face의 `from_pretrained()` 메서드를 통해 BERT 또는 DistilBERT 모델과 토크나이저를 로드하는 방법을 배운다.\n",
    "2. **토크나이저 로딩 및 토큰화 기본 실습**: 한글 문장을 입력으로 하여 토큰화 과정을 살펴보고, token IDs를 확인한다.\n",
    "3. **Forward Pass 실습**: 토큰화된 입력을 모델에 넣어서 출력(Logits, Hidden States)을 받아보고, 출력 구조를 이해한다.\n",
    "4. **다양한 모델 로드 비교**: BERT, DistilBERT, GPT-2 등 다양한 모델을 로드해보고, 각각의 출력 형태 차이를 살펴본다.\n",
    "5. **문장 임베딩 추출 실습**: BERT 기반 모델의 [CLS] 토큰 임베딩을 sentence-level 임베딩으로 활용하는 방법을 알아보고, 문장 간 유사도를 코사인 유사도로 계산하는 간단한 실습을 진행한다.\n",
    "6. **경량 모델 비교**: DistilBERT 등의 경량 모델을 사용했을 때의 차이점도 살펴본다.\n",
    "\n",
    "\n",
    "\n",
    "## 실습 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JT7PBHm9QlL7"
   },
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install sentencepiece  # 일부 토크나이저를 위해 필요할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwlCCFOrSLDv"
   },
   "source": [
    "### 1. Pre-trained Model 로딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdOYK7ZoQ98Q"
   },
   "source": [
    "**BERT 모델 & 토크나이저 로딩**\n",
    "\n",
    "- transformers 라이브러리의 from_pretrained() 메서드를 사용하면 매우 간단히 사전학습 모델과 토크나이저를 로드할 수 있다.\n",
    "- 여기서는 \"bert-base-multilingual-cased\" 모델을 예로 든다. 이 모델은 한국어를 비롯한 다양한 언어를 지원한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287,
     "referenced_widgets": [
      "a3e7879c82614d1ea02754fa4ae3b1af",
      "7e7aef711eb842229bea0d8375751c9b",
      "efdb5ad903eb4323805de4427f7e7701",
      "c840ecf6a0be448ba67ceca38342c8fb",
      "ed528adfe8764fc5b586f7799745fb32",
      "2f8c6ec6658e4a808241967ad2bd7d3a",
      "6f483e106e9e452b9658c43d430c18e0",
      "116e239b5e5840a78f09588687e25cde",
      "2e7165d5663d49aa8af715be3aceace4",
      "cabcaa5815224d3aaf6f305aaaca37da",
      "f94f04de47c24f0b988ae91da1b9266d",
      "c34394833a674c45b9dc19c325e65350",
      "fd930b68fac6454d9f2de1238458d179",
      "74d197c039144b50846efbaf0e03cf98",
      "a74909298f1a42e9a3ca824074d267c8",
      "cc36ff9e261546a99daf02024be69a59",
      "b4e2c5b1cd254b30b9ba7cb7a1724a7e",
      "7db13a19b2164ccf9a0141130c311052",
      "1373dbb08145436680e21fb5897251e4",
      "660b6466a1804d68a7049dc72fe4c101",
      "82f035759f3c419b95596d334af56565",
      "a0da9c3821cb4bd69276c31b906c1e70",
      "be43b24f7ed14719bddb08aaf9f06a80",
      "9524e4937c40422a8fcdbf354e5e5cd1",
      "7f11b39df1ec4322b4bc3e53e2daac4a",
      "ba1d749d828f4316b6382f950d0006b7",
      "ddc35da7ab5f437c889991294b5b6090",
      "e44abff612ff4d3a939231e805b2571d",
      "e025b942c81d4ebc81dc0f920218be55",
      "db64ec12da0f4bb89ff5a7b9da0278d7",
      "740109c3c2694a2994910a905b26f1ca",
      "c246aca6952244b88152a6d79a56a557",
      "c37754e0dbc040f5adf63546196096f0",
      "53e034b9913546688ebd0093785f2c9c",
      "2b952a6fad3b450e8d630cf44b16bc25",
      "25a57d185d2148cb9dd19d63a5c7962b",
      "422b1bf5deaf45468c60f68026746583",
      "b79a510df52349c9985601fa74f53537",
      "9d54a4ca3f564a8792b0fec020bfbca2",
      "76430d6947f54d7e82edb96675c2d75d",
      "26e3125b493a4822a33bfccab9256d64",
      "29bdb9ad5f184f0780ad9815f187a00f",
      "f9899562c12446a884722e4af77d92bf",
      "e9e098ea8f2e4e3ea38c10cbe1768c5f",
      "728b874d4a144b6bb47692e989c944a0",
      "84468702c72249cca6af585af144c080",
      "9d001e891b9c40328cecdce367976b52",
      "35d9a3c12a944bb8a017499b17c0adca",
      "7a54ef1da720492691a23e686dfcdba7",
      "0f85f0db8c8f4cb0b84f750a9bc440c7",
      "6b7869203ac44d6a8245d5a8c0a14207",
      "c822db9ffa3a4c858182ad5e80658def",
      "8d07ce2acb184943abbcfba1eb020afe",
      "125f9936f33e4366b0e7e2dd9cd7db41",
      "f9c465dff4f74efcb1cae89a4c4da3ec"
     ]
    },
    "executionInfo": {
     "elapsed": 40602,
     "status": "ok",
     "timestamp": 1734249235607,
     "user": {
      "displayName": "김민수",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "7-wvFV_eQpZj",
    "outputId": "31e730cb-23b6-4a64-fedb-7dc3bab16445"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e7879c82614d1ea02754fa4ae3b1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34394833a674c45b9dc19c325e65350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be43b24f7ed14719bddb08aaf9f06a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e034b9913546688ebd0093785f2c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728b874d4a144b6bb47692e989c944a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# BERT 다국어 모델 로드(https://huggingface.co/google-bert/bert-base-multilingual-cased)\n",
    "model_name = \"bert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LwsuD9nTQo0S"
   },
   "source": [
    "### 2. 토크나이저 로딩 및 토큰화 기본 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uo0_oFxrTkx8"
   },
   "source": [
    "한글 문장을 토큰화해보고, input_ids를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1734249235607,
     "user": {
      "displayName": "김민수",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "u0G3Je2nTmXM",
    "outputId": "5f86e9fe-1a6a-4a75-fd14-1c86e8ca001d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encodings: {'input_ids': tensor([[   101,   9521, 118741,  35506,  24982,  48549,    117,   9580, 118762,\n",
      "           8985,  49212,  11287,   9735,   9685,  77884,  48549,    119,    102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Input IDs: tensor([[   101,   9521, 118741,  35506,  24982,  48549,    117,   9580, 118762,\n",
      "           8985,  49212,  11287,   9735,   9685,  77884,  48549,    119,    102]])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "sentence = \"안녕하세요, 오늘 날씨가 참 좋네요.\"\n",
    "encodings = tokenizer(sentence, return_tensors=\"pt\")\n",
    "print(\"Encodings:\", encodings)\n",
    "print(\"Input IDs:\", encodings[\"input_ids\"])\n",
    "print(\"Attention Mask:\", encodings[\"attention_mask\"])\n",
    "# token_type_ids는 BERT 구조상 문장쌍 입력 시 사용됨. 단일 문장일 경우 전부 0이거나 생략될 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9-wLPVZTttb"
   },
   "source": [
    "위 출력 결과를 통해 토큰화된 결과(토큰 ID), attention mask 등을 확인할 수 있다.\n",
    "\n",
    "토큰 아이디를 실제 토큰 문자열로 다시 매핑해보면 다음과 같이 할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1734249235607,
     "user": {
      "displayName": "김민수",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "lCgmIpNHTvgk",
    "outputId": "ef5224db-5342-479f-d869-986f0f8d69d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['[CLS]', '안', '##녕', '##하', '##세', '##요', ',', '오', '##늘', '날', '##씨', '##가', '참', '좋', '##네', '##요', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(encodings[\"input_ids\"][0])\n",
    "print(\"Tokens:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y99AGgo1v3FO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFzgE1_9QoyA"
   },
   "source": [
    "### 3. 모델 Forward Pass 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 528,
     "status": "ok",
     "timestamp": 1734249370336,
     "user": {
      "displayName": "김민수",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "IEEFtOv_T18x",
    "outputId": "cdc81c7c-6b08-4a67-829c-dd486571dd1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last hidden state shape: torch.Size([1, 18, 768])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**encodings)\n",
    "\n",
    "# outputs은 Base BERT 모델일 경우, 일반적으로\n",
    "# last_hidden_state와 pooler_output(일부 모델만), hidden_states, attentions 등을 포함할 수 있다.\n",
    "# 여기서 outputs.last_hidden_state는 [batch_size, sequence_length, hidden_size] 형태의 텐서.\n",
    "print(\"Last hidden state shape:\", outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZL8HucwUl2e"
   },
   "source": [
    "- last_hidden_state: 각 토큰별 임베딩(마지막 레이어 기준)\n",
    "- pooler_output (BERT의 경우): [CLS] 토큰에 대한 임베딩을 추가로 변환한 벡터 (sentence-level representation을 제공하기 위해 사용)\n",
    "- [CLS] 토큰은 단순한 시작 토큰을 넘어 문장 전체의 정보를 요약하도록 학습되는 경향이 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 270,
     "status": "ok",
     "timestamp": 1734250145657,
     "user": {
      "displayName": "김민수",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "TSLG7sxGUh7R",
    "outputId": "c2781586-6a9e-4701-aaba-315b044b3e8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooler output shape: torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "if hasattr(outputs, 'pooler_output'):\n",
    "    print(\"Pooler output shape:\", outputs.pooler_output.shape)\n",
    "else:\n",
    "    # 단, AutoModel로 로드한 Base BERT는 pooler_output을 포함하며,\n",
    "    # AutoModelForMaskedLM 등의 다른 헤드 모델은 구조가 다를 수 있음.\n",
    "    print(\"이 모델은 pooler_output을 제공하지 않습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RwD83MPMSXml"
   },
   "source": [
    "### 4. 다양한 모델 로드해보기 (DistilBERT, GPT-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btgne6ssU3rU"
   },
   "source": [
    "DistilBERT 로드\n",
    "DistilBERT는 BERT보다 파라미터 수가 적고 빠른 추론이 가능하며, 성능은 비교적 비슷한 경량 모델이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2190,
     "status": "ok",
     "timestamp": 1734250340754,
     "user": {
      "displayName": "김민수",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "ZQ8rXIJDU3WD",
    "outputId": "c194ba72-a69d-48e9-a180-59597c94ff0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT last_hidden_state shape: torch.Size([1, 18, 768])\n",
      "이 모델은 pooler_output을 제공하지 않습니다.\n"
     ]
    }
   ],
   "source": [
    "distil_name = \"distilbert-base-multilingual-cased\"\n",
    "distil_tokenizer = AutoTokenizer.from_pretrained(distil_name)\n",
    "distil_model = AutoModel.from_pretrained(distil_name)\n",
    "\n",
    "distil_encodings = distil_tokenizer(sentence, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    distil_outputs = distil_model(**distil_encodings)\n",
    "\n",
    "print(\"DistilBERT last_hidden_state shape:\", distil_outputs.last_hidden_state.shape)\n",
    "\n",
    "# DistilBERT는 pooler_output이 없는 경우가 많다.\n",
    "if hasattr(distil_outputs, 'pooler_output'):\n",
    "    print(\"Pooler output shape:\", distil_outputs.pooler_output.shape)\n",
    "else:\n",
    "    print(\"이 모델은 pooler_output을 제공하지 않습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GICaXC7bU6GM"
   },
   "source": [
    "GPT-2 로드\n",
    "- GPT-2는 Decoder 기반 언어 모델로, causal language modeling 목적으로 사전학습되었다.\n",
    "- 한국어 지원 모델을 찾을 수도 있으나 여기서는 기본 gpt2 영문 모델을 예로 들어 출력 구조 차이를 살펴본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227,
     "referenced_widgets": [
      "ed49bf60018349a393ba78d1235a4d57",
      "d44ebdf716984d21bdbd2ab86c3bf5c7",
      "c2b1e4126fe14912b2b4b18f45db6c5e",
      "f1dd57d1be724b50b2d0c810d3b0eaee",
      "aa0c455290d64ad0aea1650f36288e97",
      "3870224b110a4bc59d259d356949a774",
      "377c2fd1fba044aa909dfa9bbe7fc5f7",
      "65578f7c450c4e54ae9317ac2232b0cd",
      "ff4e84ce5cc245a998d34d81722436b3",
      "af56617bb97140fea81c925427a15ef4",
      "47d2b9f2533d4e29a5f0af6d90e4a051",
      "b9cd457dae8a4eceaa227c812851e13f",
      "68906017bc874dd28f954dbf96b79143",
      "b170210fbbd44fb4a731cd40663a2d05",
      "6276b5e8258040288a6cdac2305ca1de",
      "03f5f1dfa34e4318b7263ffdbe3d3429",
      "c8c9330a8e5049cc8ad6ce596b410d85",
      "033b8d5e3993481fa89e205e3c6b7995",
      "532afedf012848909ceb7aef8ac3c22a",
      "7ad3ed1fdf564496b661195414e0e1d4",
      "cc7354dc00644959a45f43a9a726f01d",
      "43f69c0171c1480dbad1545aea416dec",
      "97aed02011504eb583f3ae3b1a34ee42",
      "af8479c0c2cf4497b9e66b759b3237f7",
      "2cd2bc38746d403d9f090e409c6d4128",
      "e88c68be14f04c6ab55dc32d618e3120",
      "1a1a2ee3c7564cc4883d98ee726a8c5c",
      "ad376ecd4e274fedb9da5bb8a9a354e8",
      "dc010c4a9b6f48fc9649c31ce4e25039",
      "c441336e2d334fa5b194493fde321b19",
      "f1a27c80e4484a139646d579a6532b71",
      "da07b5239cb641568564fdc098157356",
      "8ec5f081ec694908876bfc5b3c806d95",
      "9264609eee9149a2b54dbe2e083a0243",
      "ca60fab8220245f3ab8c5fe54f7a0bf5",
      "69459449f9be4cd490abc154fe565f38",
      "30d4acde7fd74c16b5b34ebe4ba2c955",
      "65a83430a01f4b1e832a9ca3d85d378e",
      "8b219195f35044489e9b162a01ade4cc",
      "f382e123a8b64cf09ae937273f0776c3",
      "8d3be14e19294b84bb6da75799e7d419",
      "d55225c8901c40cba25dd153f992e0e0",
      "ad47db1094cc4044bb5a3ad44afe63d3",
      "6bcf84d763da4cc6b76a83c634cb958f",
      "0e3890cfd819467680df31917858a26f",
      "ca6b8a793d6e4bd98c47a459f5b9320d",
      "9d64d3876c964827b83ba7064705c9d0",
      "cb879f2b24af41e0bcc0a681e87c33e5",
      "3a7289e583514ba39d84bbfd04839d18",
      "604f3ea1c8c3426f9902541469d9463c",
      "4ae699d9c0c843779a2f6b46f87e2a34",
      "82159bd9a3524de2b5376ae5f5d85e33",
      "53ad5cdc8f574168bbfcfd3511c521f6",
      "e0748ba8b8a8445f9c44c9930a4a02fe",
      "30e1f3acc81246f8913a00ca14c8c5b1",
      "cb05da32895a486f84647f1f79e44714",
      "fd849e4d26544108b90973bfedbb3fd3",
      "c87bfe7129c740a08f1c2bcd0b532cc7",
      "76c0c8ff869c47579aae60fc26ba782e",
      "4bbf2c24360f4821995025d80d7e49d4",
      "0616a3ae8d234983b017376f327b6597",
      "3a88007bda8a4e67b81df4a0a64f6b75",
      "fd4495ecbf384abe94bcb81606a1d367",
      "3654972832de4d029483ce64fe596791",
      "b59d38f7cb1e4667b7f164fcacfce04e",
      "40b47c378a724095ab0eac4524ebfa1d"
     ]
    },
    "executionInfo": {
     "elapsed": 10709,
     "status": "ok",
     "timestamp": 1734249647177,
     "user": {
      "displayName": "김민수",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "OXuaw1u2U7EO",
    "outputId": "96ce89f6-62ab-4649-e02e-bc8970ac65ba"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed49bf60018349a393ba78d1235a4d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9cd457dae8a4eceaa227c812851e13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97aed02011504eb583f3ae3b1a34ee42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9264609eee9149a2b54dbe2e083a0243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3890cfd819467680df31917858a26f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb05da32895a486f84647f1f79e44714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 last_hidden_state shape: torch.Size([1, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "gpt2_name = \"gpt2\"\n",
    "gpt2_tokenizer = AutoTokenizer.from_pretrained(gpt2_name)\n",
    "gpt2_model = AutoModel.from_pretrained(gpt2_name)\n",
    "\n",
    "gpt2_encodings = gpt2_tokenizer(\"Hello world!\", return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    gpt2_outputs = gpt2_model(**gpt2_encodings)\n",
    "\n",
    "print(\"GPT-2 last_hidden_state shape:\", gpt2_outputs.last_hidden_state.shape)\n",
    "# GPT-2는 [batch_size, sequence_length, hidden_size] 형태의 last_hidden_state를 반환하며,\n",
    "# pooler_output이나 CLS 토큰 개념이 없습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNdGa1ZBU-LZ"
   },
   "source": [
    "이처럼 모델별로 출력 형태와 활용 방식이 다를 수 있음을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2blpoYl2SaYy"
   },
   "source": [
    "### 5. 문장 임베딩 추출 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1JZTEc-VAKT"
   },
   "source": [
    "BERT 기반 모델에서 문장 임베딩을 얻는 한 가지 방법은 [CLS] 토큰 임베딩을 사용하는 것이다. [CLS] 토큰은 문장 전체를 대표하는 토큰으로 간주되며, BERT는 이를 통해 문장 단위 태스크를 수행하도록 학습되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1734249647177,
     "user": {
      "displayName": "김민수",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "KBsv9QzLVBd0",
    "outputId": "ea9ed6d4-4eb5-4b0e-a0a8-4c81d8594b69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLS embedding shape: torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    bert_outputs = model(**encodings)\n",
    "# bert_outputs.last_hidden_state: [batch_size, seq_length, hidden_size]\n",
    "# 첫 번째 토큰 [CLS] 임베딩을 추출\n",
    "cls_embedding = bert_outputs.last_hidden_state[:, 0, :]  # [batch_size, hidden_size]\n",
    "print(\"CLS embedding shape:\", cls_embedding.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1734250755944,
     "user": {
      "displayName": "김민수",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "1fx-RG6LZXYd",
    "outputId": "014e34d6-fa2f-4ae2-b3a0-31fb8763f635"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1557,  0.0021,  0.2183,  0.0628,  0.1071,  0.4759,  0.0425,  0.2050,\n",
       "         -0.3615,  0.3048]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_outputs.pooler_output[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 252,
     "status": "ok",
     "timestamp": 1734250763656,
     "user": {
      "displayName": "김민수",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "rLQ0_6njZVNE",
    "outputId": "dca691e3-5cf1-4b50-e421-8b21c2c4556e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1557,  0.0021,  0.2183,  0.0628,  0.1071,  0.4759,  0.0425,  0.2050,\n",
       "         -0.3615,  0.3048]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.pooler_output[:,:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwOcDSuQVDk_"
   },
   "source": [
    "cls_embedding는 해당 문장을 대표하는 임베딩으로 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tkSjvgnSc_9"
   },
   "source": [
    "### 6. DistilBERT 등 경량 모델과의 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yc1FuDT4VGal"
   },
   "source": [
    "DistilBERT도 문장 임베딩용으로 사용 가능하나, pooler나 [CLS] 토큰 활용 방식이 다를 수 있으므로 보통 마지막 히든 스테이트의 평균(Mean Pooling) 등을 통해 문장 임베딩을 얻는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1734249647593,
     "user": {
      "displayName": "김민수",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "tC_1Ai3DVC8N",
    "outputId": "b4d6cec6-e560-4aeb-e880-4429df8f226f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBERT CLS embedding shape: torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    distil_outputs = distil_model(**distil_encodings)\n",
    "\n",
    "# DistilBERT에는 CLS 토큰이 첫 토큰에 해당하나 pooler_output이 없으므로 마지막 히든 스테이트 첫 토큰을 사용하거나,\n",
    "# 혹은 mean pooling을 사용할 수 있다.\n",
    "distil_cls_embedding = distil_outputs.last_hidden_state[:, 0, :]\n",
    "print(\"DistilBERT CLS embedding shape:\", distil_cls_embedding.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uU2J3XvSc93"
   },
   "source": [
    "### 7. 임베딩 간 유사도 계산 (코사인 유사도)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTHEMwW6VJFz"
   },
   "source": [
    "문장 임베딩을 얻었으니, 두 문장 간 유사도를 계산해보자. 코사인 유사도를 사용하면 쉽게 비교 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1734249647593,
     "user": {
      "displayName": "김민수",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "ZFTey6vDVKKJ",
    "outputId": "bae75e0d-14e1-42fd-8aee-7c5a39e93092"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.9361767768859863\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "sentences = [\"오늘 날씨가 좋네요.\", \"정말 맑고 화창한 날씨네요.\"]\n",
    "encodings_1 = tokenizer(sentences[0], return_tensors=\"pt\")\n",
    "encodings_2 = tokenizer(sentences[1], return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    out1 = model(**encodings_1)\n",
    "    out2 = model(**encodings_2)\n",
    "\n",
    "cls_embed_1 = out1.last_hidden_state[:,0,:]\n",
    "cls_embed_2 = out2.last_hidden_state[:,0,:]\n",
    "\n",
    "# 코사인 유사도 계산\n",
    "cos_sim = F.cosine_similarity(cls_embed_1, cls_embed_2)\n",
    "print(\"Cosine similarity:\", cos_sim.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89GEXSw7VMIY"
   },
   "source": [
    "- 코사인 유사도 값이 1에 가까울수록 매우 유사한 의미의 문장, -1에 가까울수록 매우 다른 의미의 문장임을 나타낸다.\n",
    "\n",
    "- 유사한 문장 (\"오늘 날씨가 좋네요.\" vs \"정말 맑고 화창한 날씨네요.\")의 경우 높은 유사도(0.8 이상)가 나올 것으로 기대할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZOnqRGmSkpt"
   },
   "source": [
    "### 8. 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzv1KJYRSpqK"
   },
   "source": [
    "- from_pretrained() 메서드를 통해 손쉽게 모델과 토크나이저를 로드할 수 있다.\n",
    "- 토크나이저를 사용해 입력 문장을 토큰화하고, input_ids, attention_mask, token_type_ids 등을 확인할 수 있다.\n",
    "- 다양한 모델(BERT, DistilBERT, GPT-2)을 로드하고 Forward Pass를 수행해보면, 각 모델의 출력 형식(히든 스테이트, pooler_output, etc.)에 대한 이해를 넓힐 수 있다.\n",
    "- BERT 기반 모델에서 [CLS] 토큰 임베딩을 문장 임베딩으로 활용할 수 있으며, 임베딩 간 유사도(코사인 유사도) 계산을 통해 문장 간 의미적 유사도를 파악할 수 있다.\n",
    "- DistilBERT 등의 경량 모델을 사용해도 유사한 과정을 수행할 수 있으며, 필요한 경우 mean pooling 등 다른 방법으로 문장 임베딩을 얻을 수 있다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6HluRVMz1oL"
   },
   "source": [
    "# BERT 모델 파인튜닝을 활용한 챗봇 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WdkDHf10S0Q"
   },
   "source": [
    "## BERT란?\n",
    "BERT(Bidirectional Encoder Representations from Transformers)는 구글에서 개발한 사전 훈련된 자연어 처리 모델로, 다양한 언어 이해 태스크에서 뛰어난 성능을 발휘합니다. BERT의 핵심은 트랜스포머 아키텍처의 양방향 인코더를 사용하는 것입니다.\n",
    "\n",
    "## 핵심 기술\n",
    "### 트랜스포머 모델\n",
    "트랜스포머는 '어텐션 메커니즘'을 사용하여 입력 데이터의 각 요소 간의 관계를 학습합니다. BERT는 이 트랜스포머의 인코더 구조만을 사용합니다.\n",
    "\n",
    "### 양방향 훈련\n",
    "BERT의 또 다른 중요한 특징은 양방향으로 문맥을 이해합니다. 이는 기존 단방향 또는 양방향이 제한된 모델들과 비교하여 문맥 파악에 더욱 효과적입니다.\n",
    "\n",
    "## 사전 훈련 태스크\n",
    "BERT는 두 가지 주요 태스크를 통해 사전 훈련됩니다.\n",
    "\n",
    "<img src=\"https://velog.velcdn.com/images/tm011899/post/72149edb-a1f0-46e0-aebe-4e89c0a490ae/image.PNG\" width=\"600\">\n",
    "\n",
    "1. **Masked Language Model (MLM)**\n",
    "   - 무작위로 선택된 토큰을 마스킹하고, 마스킹된 토큰을 예측하도록 합니다. 이 과정에서 모델은 양방향 문맥을 고려해야만 정확한 예측이 가능합니다.\n",
    "2. **Next Sentence Prediction (NSP)**\n",
    "   - 두 개의 문장이 주어졌을 때, 두 번째 문장이 첫 번째 문장의 다음 문장인지 관계 없는 문장인지 예측합니다. 이 태스크는 특히 문서 수준의 이해와 관계 추론에 도움을 줍니다.\n",
    "\n",
    "## 활용 예\n",
    "BERT는 자연어 이해 관련 다양한 태스크에 적용될 수 있습니다. 예를 들어, 감성 분석, 질문 응답 시스템, 문장 분류 등에 활용되어 우수한 결과를 도출합니다.\n",
    "\n",
    "## 성과\n",
    "BERT는 출시되자마자 여러 벤치마크에서 최고 성능을 기록하며, NLP 분야에서 새로운 기준을 설정했습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J7waf7xjquVx"
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "438a1772be1545528426306cb8747df4",
      "ef6a114ad1644dfb8439a7681434273f",
      "4f0b76ba2219407d9d9fc03954e596f4",
      "d90f586f983a4d6bbd8524a8234fd140",
      "4546df75e69c49098120f1c37e45c5d8",
      "6beb88ef9e7a4830b5b35ce2b5aba17e",
      "0557ad6648424f46b610834ddd1f59e4",
      "dfd685ba6b5d40e99eb119c60296676b",
      "079694b48f68432fb29f7409f6a13ce3",
      "70061a8017944ee5a7a42314a0cf7388",
      "ccc1f474791643d59975e3af15165fb8",
      "88333deef31345979012e1985184ebef",
      "4c7b328bd22543c6942cad9576d610d7",
      "ca0360968e0e48119a08ba503de0a583",
      "aac7d2f2833b40fb809207ea378539a1",
      "f9434331c4af4867a88157f23ffdc10a",
      "4c04ff1f506d40f894eee80261c273d7",
      "5ff55cfd2c2d4201bfcdedf874787b0d",
      "93135d19c327487395ba7a00a85af6de",
      "08f62365fab8440fb63f37fc32bbfed6",
      "0d4e18d99c2041a085e42cc22e72a1a5",
      "4950eef80eb84358ac5fc1217cfd68e2",
      "86b4c25895cc4701ad8ffca87b9111e1",
      "da3f683b0e684604b00fffe60e7ca38b",
      "4e57dcc04d72442493a44d1fd257e37b",
      "1122661ec7634269883238fd96396149",
      "94820df6212f4108abbb4c8a49f63277",
      "f68577045c0840aa85586d06c9199bc5",
      "3c1ab5b3c6e0436081c7958c204a9cf5",
      "38341915fa354238aa40c1dd756288eb",
      "314467fa6ed9436fa111af68e49887b2",
      "2425a9ccbea8415fbe1ccad2081bddc7",
      "ec3000c16d3a462abbc10ed004f324f3",
      "ae5c383d5e634164a736f3f998e3593c",
      "2498a43a3d614377af4045159ed98857",
      "9d7edf08a4ac44e8b520d767dcc68d81",
      "f4b55938d77645cf883d8ff0733d1a33",
      "13ba5377b000460698ae4867d725340e",
      "b91fcf5ac05e41acbadb98f83a205929",
      "75e69fb59be74accac0aa07b026e2050",
      "3406f3e073db49d79f3811d035e1a423",
      "ef904ee9a9e3429ca452bb1b64aeb2a3",
      "2079e1fa23b54c90a2e322083196e677",
      "498db1cbbfc04e8e94dea8a48b5b8729",
      "66d6a1cef8a14aac969d69565e97840f",
      "56a8433925a74c1aa8188b128fdfd02a",
      "0bcf299a7e5b4bbe9ad591a29081e32c",
      "6e4f39fbadaf48cb8a25558a5ae7d3e5",
      "72911ecc582141bb844f6e18574a8e1f",
      "ed639ca930cf43e59037e90bc1d1e1bc",
      "fab508ee8e6a4e22953c35c5ec60ea46",
      "84f77eac4df34b8b8468f50fe1260536",
      "96446130cac74343abed1e0fbca34b3a",
      "cb0ac3e37189497a88aceb9fea32a3e3",
      "00ab498a7d6d42af88f4a11e91911804",
      "a98f502beadf476cb336be768fd232f9",
      "7d022b0db2c34a4f9ea9ca4d7492c4c3",
      "aebb07fa7a5f47cab284638450215114",
      "d0442c286365419aa0fdc234d0003cfe",
      "16bfe224fcdc4625aeaf4a28508b5042",
      "faf0527ff9134bf1841d7bc113359790",
      "75821589bddb47039f569a1ed3fd42d0",
      "6fc7f987b6e643b0b0bbb845dabac794",
      "e050fd98817141738459ce698d965932",
      "70436209e1624d19b07185e1cd9d56d6",
      "7dc60a36eb084fd3b716d9b2a2ad192e",
      "8ed5537618734f3dbd462b09ee9a5a07",
      "b41b92cf9a72471f94234d089a981eca",
      "6d2db3be7d7d42b2bc4d9b39c30ebf80",
      "05e01aff72b1469da8b77d39ff2584a4",
      "83f22bd4dc6a4d70a269c3eebb217210",
      "5467d48c6d854620a7e6e31296e55160",
      "584462b01d784fed97051d501bf57e3a",
      "d95c3ec152944c9ebcc6f56fef500052",
      "af9049f261624fbf8b75ea47f57a0702",
      "5d052523ee18468abff495b09af78785",
      "12d18b8076a74bf891bb4ed30753d8aa"
     ]
    },
    "executionInfo": {
     "elapsed": 47390,
     "status": "ok",
     "timestamp": 1734370176578,
     "user": {
      "displayName": "김민수",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "sjaHTEQ9z4TA",
    "outputId": "202555ae-a178-4c96-fb8a-49b659a79645"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438a1772be1545528426306cb8747df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88333deef31345979012e1985184ebef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b4c25895cc4701ad8ffca87b9111e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae5c383d5e634164a736f3f998e3593c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d6a1cef8a14aac969d69565e97840f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.bert.modeling_bert.BertModel'> is overwritten by shared encoder config: BertConfig {\n",
      "  \"_name_or_path\": \"klue/bert-base\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.bert.modeling_bert.BertLMHeadModel'> is overwritten by shared decoder config: BertConfig {\n",
      "  \"_name_or_path\": \"klue/bert-base\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": true,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.46.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "챗봇 샘플의 개수 : 11662\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98f502beadf476cb336be768fd232f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10495 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4114: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed5537618734f3dbd462b09ee9a5a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1167 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 처리 및 학습을 위한 라이브러리 임포트\n",
    "from transformers import BertTokenizer, EncoderDecoderModel, EncoderDecoderConfig, Trainer, TrainingArguments,AutoConfig\n",
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd                 # 데이터프레임과 CSV 파일 처리를 위한 라이브러리\n",
    "import urllib.request               # URL에서 파일 다운로드를 위한 라이브러리\n",
    "import time                         # 학습 시간 측정을 위한 라이브러리\n",
    "import numpy as np                  # 수학 계산 및 배열 처리를 위한 라이브러리\n",
    "import matplotlib.pyplot as plt     # 그래프 및 데이터 시각화를 위한 라이브러리\n",
    "import torch\n",
    "import re                           # 정규 표현식 처리를 위한 라이브러리\n",
    "\n",
    "# 챗봇 데이터 다운로드 및 로드\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\",\n",
    "    filename=\"ChatBotData.csv\")  # URL에서 챗봇 데이터를 로컬로 다운로드\n",
    "\n",
    "# BERT 토크나이저와 모델을 초기화합니다.\n",
    "tokenizer = BertTokenizer.from_pretrained('klue/bert-base')\n",
    "config = EncoderDecoderConfig.from_encoder_decoder_configs(\n",
    "    encoder_config=AutoConfig.from_pretrained('klue/bert-base'),\n",
    "    decoder_config=AutoConfig.from_pretrained('klue/bert-base')\n",
    ")\n",
    "# 디코더의 시작 토큰 ID를 설정합니다.\n",
    "config.decoder_start_token_id = tokenizer.cls_token_id  # CLS 토큰을 시작 토큰으로 사용\n",
    "# 패딩 토큰 ID도 설정할 필요가 있습니다.\n",
    "config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# 설정된 구성을 바탕으로 모델을 초기화합니다.\n",
    "model = EncoderDecoderModel(config=config)\n",
    "\n",
    "# GPU 사용이 가능한 환경이라면, 모델을 GPU로 이동시킵니다.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# CSV 파일에서 데이터를 로드하고, 결측치를 확인 및 처리합니다.\n",
    "df = pd.read_csv('ChatBotData.csv')\n",
    "# 중복데이터 제거\n",
    "df = df.drop_duplicates(subset='Q', keep='first')\n",
    "print('챗봇 샘플의 개수 :', len(df))\n",
    "\n",
    "\n",
    "# 질문과 답변 데이터 전처리\n",
    "questions = df['Q'].apply(lambda x: re.sub(r\"([?.!,])\", r\" \\1 \", x).strip())\n",
    "answers = df['A'].apply(lambda x: re.sub(r\"([?.!,])\", r\" \\1 \", x).strip())\n",
    "\n",
    "# 토크나이징 및 데이터셋 변환\n",
    "def tokenize_function(examples):\n",
    "    model_inputs = tokenizer(examples['questions'], max_length=40, truncation=True, padding='max_length')\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples['answers'], max_length=40, truncation=True, padding='max_length')['input_ids']\n",
    "    model_inputs['labels'] = labels\n",
    "    return model_inputs\n",
    "\n",
    "# 데이터셋을 훈련 및 검증용으로 나눕니다.\n",
    "train_size = int(0.9 * len(questions))\n",
    "train_dataset = Dataset.from_dict({'questions': questions[:train_size], 'answers': answers[:train_size]})\n",
    "val_dataset = Dataset.from_dict({'questions': questions[train_size:], 'answers': answers[train_size:]})\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3932705,
     "status": "ok",
     "timestamp": 1734374109280,
     "user": {
      "displayName": "김민수",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "Zpfa-zcLqb7A",
    "outputId": "fd6732cf-510e-474a-c53c-35ae95406d86"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ··········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20241216_173603-38g1gxhz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/minsukim/huggingface/runs/38g1gxhz' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/minsukim/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/minsukim/huggingface' target=\"_blank\">https://wandb.ai/minsukim/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/minsukim/huggingface/runs/38g1gxhz' target=\"_blank\">https://wandb.ai/minsukim/huggingface/runs/38g1gxhz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:629: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:649: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1640' max='1640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1640/1640 58:59, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.542400</td>\n",
       "      <td>9.344317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.137200</td>\n",
       "      <td>7.869624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.226400</td>\n",
       "      <td>5.880588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.873900</td>\n",
       "      <td>3.499101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.345000</td>\n",
       "      <td>1.416778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.886800</td>\n",
       "      <td>1.033488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.803700</td>\n",
       "      <td>0.972997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.714200</td>\n",
       "      <td>0.945585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.656600</td>\n",
       "      <td>0.934352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.623800</td>\n",
       "      <td>0.922413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.599000</td>\n",
       "      <td>0.924995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.564800</td>\n",
       "      <td>0.919953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.527500</td>\n",
       "      <td>0.919659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.513000</td>\n",
       "      <td>0.926541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.474400</td>\n",
       "      <td>0.926546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.455600</td>\n",
       "      <td>0.926907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.426700</td>\n",
       "      <td>0.932189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.418700</td>\n",
       "      <td>0.933352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.407000</td>\n",
       "      <td>0.936447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.405900</td>\n",
       "      <td>0.936567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:629: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:649: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:629: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:649: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:629: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:649: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:629: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  decoder_attention_mask = decoder_input_ids.new_tensor(decoder_input_ids != self.config.pad_token_id)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:649: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1640, training_loss=2.0652259881903485, metrics={'train_runtime': 3930.0477, 'train_samples_per_second': 53.409, 'train_steps_per_second': 0.417, 'total_flos': 1.0059763181568e+16, 'train_loss': 2.0652259881903485, 'epoch': 20.0})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 트레이너 설정을 정의합니다.\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=256,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\"  # 각 에폭마다 검증 데이터로 평가\n",
    ")\n",
    "\n",
    "# 트레이너 인스턴스를 생성하고 모델을 훈련합니다.\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "su5OFZcyxDLR"
   },
   "outputs": [],
   "source": [
    "# 사용자 입력에 대해 모델을 사용하여 응답을 생성하는 함수를 정의합니다.\n",
    "def chat(question):\n",
    "    inputs = tokenizer(question, return_tensors='pt', max_length=40, truncation=True, padding=\"max_length\")\n",
    "    inputs.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(inputs['input_ids'])\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 928,
     "status": "ok",
     "timestamp": 1734374979353,
     "user": {
      "displayName": "김민수",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "CvhQEWlLxD9a",
    "outputId": "ff5f26e9-426a-4eca-b9a3-d98b72100a70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잘할 수 있을 거예요.\n"
     ]
    }
   ],
   "source": [
    "# 챗봇 테스트 예시\n",
    "print(chat(\"고민이 있어\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 956,
     "status": "ok",
     "timestamp": 1734374893393,
     "user": {
      "displayName": "김민수",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "Uyss1pahfLw6",
    "outputId": "9bf19911-e6ae-4118-9398-a1c7dd472e0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잘할 수 있을 거예요.\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"미래는 어떨까?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 944,
     "status": "ok",
     "timestamp": 1734374936116,
     "user": {
      "displayName": "김민수",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "q4g5YWZlzKE0",
    "outputId": "0cf55d34-4eae-481f-8d39-9050422dc81d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "좋은 곳으로 가보세요.\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"카페갈래?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 450,
     "status": "ok",
     "timestamp": 1734374961553,
     "user": {
      "displayName": "김민수",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "YwVCNtVjzW49",
    "outputId": "88ad1a31-0e84-4f81-d63b-00cd7d71a44f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자신을 더 사랑해주세요.\n"
     ]
    }
   ],
   "source": [
    "print(chat(\"너무 화가나\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOI33mZeiLPNSWmuoVzb2gG",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
