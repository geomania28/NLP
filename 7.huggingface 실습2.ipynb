{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jpuXkJtm6m8S"
   },
   "source": [
    "# Hugging Face Pipeline ê°œìš” ë° í™œìš©\n",
    "\n",
    "## 1. Pipeline API ê°œë… ë° í™œìš© ë²”ìœ„  \n",
    "Hugging Faceì˜ `pipeline` APIëŠ” NLP ëª¨ë¸ í™œìš©ì„ ê°„ì†Œí™”í•˜ê³  ì¶”ìƒí™”í•œ ê³ ìˆ˜ì¤€ ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤.  \n",
    "- **ê°œë…**: ë³µì¡í•œ ëª¨ë¸ ë¡œë”©, í† í°í™”, ì¶”ë¡  ê³¼ì •ì„ í•œ ë²ˆì— ì²˜ë¦¬í•˜ëŠ” ê°„ë‹¨í•œ í•¨ìˆ˜ í˜¸ì¶œ í˜•íƒœì˜ API.  \n",
    "- **ì¥ì **: ëª¨ë¸ í™œìš© ì‹œ í•„ìˆ˜ì ì¸ ì „ì²˜ë¦¬(í† í°í™”) â†’ ëª¨ë¸ ì¶”ë¡  â†’ í›„ì²˜ë¦¬(ê²°ê³¼ í•´ì„) ê³¼ì •ì„ ëª¨ë‘ ë‚´ë¶€ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ë¯€ë¡œ, ì‚¬ìš©ìëŠ” ëª¨ë¸ ì‚¬ìš© ë¡œì§ì„ ê°„ë‹¨íˆ ìœ ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
    "- **í™œìš© ë²”ìœ„**: ê°ì • ë¶„ì„(Sentiment Analysis), ì œë¡œìƒ· ë¶„ë¥˜(Zero-Shot Classification), ì§ˆì˜ì‘ë‹µ(Question Answering), ë²ˆì—­(Translation), ìš”ì•½(Summarization), í‚¤ì›Œë“œ ì¶”ì¶œ ë“± ë‹¤ì–‘í•œ NLP íƒœìŠ¤í¬ì— ì‰½ê²Œ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCC_dbt56m6M"
   },
   "source": [
    "## 2. ë‹¤ì–‘í•œ Pipeline ì‚¬ë¡€  \n",
    "- **Sentiment Analysis**: ì…ë ¥ ë¬¸ì¥ì˜ ê°ì •(ê¸ì •, ë¶€ì • ë“±)ì„ ì¶”ë¡ í•˜ëŠ” íŒŒì´í”„ë¼ì¸.  \n",
    "- **Zero-Shot Classification**: ë¯¸ë¦¬ ì •ì˜ë˜ì§€ ì•Šì€ ë ˆì´ë¸”ì— ëŒ€í•´ ë¬¸ì¥ì„ ë¶„ë¥˜í•  ìˆ˜ ìˆëŠ” íŒŒì´í”„ë¼ì¸.  \n",
    "- **Question-Answering(QA)**: ë¬¸ì„œ(ì»¨í…ìŠ¤íŠ¸)ì™€ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ í•´ë‹¹í•˜ëŠ” ë‹µì„ ì¶”ë¡ í•˜ëŠ” íŒŒì´í”„ë¼ì¸.  \n",
    "- **Summarization**: ê¸´ ë¬¸ì„œë¥¼ ìš”ì•½ë¬¸ìœ¼ë¡œ ì••ì¶•í•˜ëŠ” íŒŒì´í”„ë¼ì¸.  \n",
    "- **Translation**: í•˜ë‚˜ì˜ ì–¸ì–´ë¡œ ëœ ë¬¸ì¥ì„ ë‹¤ë¥¸ ì–¸ì–´ë¡œ ë²ˆì—­í•˜ëŠ” íŒŒì´í”„ë¼ì¸.\n",
    "\n",
    "ì—¬ê¸°ì„œëŠ” íŠ¹íˆ **ì§ˆì˜ì‘ë‹µ(Question Answering) Pipeline**ì— ì´ˆì ì„ ë§ì¶° ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5RsZIB_zpKb"
   },
   "source": [
    "## 3. ì§ˆì˜ì‘ë‹µ(QA) Pipeline ê°œìš”  \n",
    "**Question-Answering Pipeline**ì€ ì£¼ì–´ì§„ ë¬¸ì„œ(ì»¨í…ìŠ¤íŠ¸)ì™€ í•˜ë‚˜ì˜ ì§ˆë¬¸ì„ ì…ë ¥ë°›ê³ , í•´ë‹¹ ë¬¸ì„œ ë‚´ì—ì„œ ë‹µì„ ì¶”ì¶œí•˜ëŠ” íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.  \n",
    "- ì…ë ¥:  \n",
    "  - `context`: ì§ˆë¬¸ì— ëŒ€í•œ í•´ë‹µì„ í¬í•¨í•˜ê³  ìˆì„ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë˜ëŠ” í…ìŠ¤íŠ¸ ë¬¸ì„œ  \n",
    "  - `question`: ë‹µì„ ì–»ê³ ì í•˜ëŠ” íŠ¹ì • ì§ˆë¬¸  \n",
    "- ì¶œë ¥:  \n",
    "  - ë¬¸ì„œ ë‚´ì—ì„œ ì¶”ì¶œí•œ ì •ë‹µ ë¬¸ìì—´ê³¼ í•´ë‹¹ ì •ë‹µì˜ ì ìˆ˜, ìœ„ì¹˜ ì •ë³´ ë“±ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "## 4. QA Pipeline ì‚¬ìš©ë²•\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416,
     "referenced_widgets": [
      "2f995af1fdf24fdbaa844af4fe4c7000",
      "7e5af6845a87404d8fbff586c1c6bd1c",
      "3728a33d673741268a4a8af9f26f8252",
      "37a68544de8c4e9a9b8796f7ed29eb8d",
      "1a0fd324379a4eb39156340228f28fc0",
      "a58917252f204147877d1e9befc34a36",
      "b1166fa149e84b78a49c8311fa994902",
      "7f7603628d69497184dd67c6de397fe0",
      "269ed9d1ff244bd7a5b6ef56719789a3",
      "ed604c9de56140aa8085354b7c400f00",
      "a6d3b55e867340ee81334bce3afe0b82",
      "5072c82a6a7243cb84dac5463786b224",
      "835c94cde84d49ca85381c3578bb98e3",
      "0e64ae6a10fe4fec989ce543d6337e71",
      "bdc18985f22948508be05bf1a141b0a2",
      "33bf72ca81a14f5d9fe2541d41e21819",
      "a56d791002d84932a5953704a000b463",
      "edd02403788e43db9e6e604b09bc60c9",
      "69421a637f9d43708ab2048189da6e46",
      "62a13be30699427bbd22cd6b479eafeb",
      "e18b78486b2b4c0aa8831abae1f01f61",
      "a7e03b8c42844bed8f07c228509c2db7",
      "6f4efc3dddef4339ad98c53db01a4ea7",
      "6bc13c2a09db4aeead307c68cd3cf02a",
      "4e05300860a847b1a16d00484e245e96",
      "f93d3325785946719e1ad5aeb4b30e6c",
      "7ca54cd3d2e54629b06957e725f1110a",
      "bf7d4febb4224588977ef501e9716389",
      "600bbeb24a254ee7b588fd877866784d",
      "2dd2c4435b59436e8327c2febb1cb5e4",
      "9f59454087524d8ea659eb307e8ab666",
      "d49656d207db4d59be5659c562031425",
      "3ed70f8126d04a89bd7f5b05c55cf320",
      "2e3392a381c1403cbeb9451a15b742e8",
      "e5984e2642804b40bb07989794323e93",
      "a80080d64dcf450cb966f3eaba295926",
      "e87f7406298b417c9eb88639328d76ab",
      "9ae2a0eb4f6b4790baad201dede10824",
      "04d1205b42534c098e57536299623f07",
      "4f824f9171cd4cb4b490ecefd4016cab",
      "8f04fc9d28ce45d0a81fdc761677b6ff",
      "e2326ae3ee7e49a1bb1b8a9fd31d4227",
      "3b9e897a51e349348b7000201691145f",
      "4baa512acfba4d6aafefd4961a5d3cf6",
      "ae9051d423f34392b0613bac36ca95e1",
      "66ed7f23801d4521a6fe51bd7b25aa88",
      "83a4a47038e34d0faacb7945b7b02e9f",
      "6f28eb778b724f39833a2c01ac645216",
      "4ebd36fe9aab4abbacb1a31b6f1df521",
      "16012682e2b746dc8eed30bc55edad92",
      "c7b0c96956b84c3b823d5dd19b36cc3e",
      "e6f089f6fe9e49d5941281abb3829886",
      "6ef5e70cbbc6459d8ed1bbf75c3b9a6d",
      "d66ffb4d61524549a0b1087b89fd79b6",
      "bdaa35848d0a43d086c9d4d6c224aa3f"
     ]
    },
    "executionInfo": {
     "elapsed": 45406,
     "status": "ok",
     "timestamp": 1734414631267,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "LAsUz6ijzk5Y",
    "outputId": "d5fc8222-5d14-460b-b484-f557545c3a49"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f995af1fdf24fdbaa844af4fe4c7000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5072c82a6a7243cb84dac5463786b224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f4efc3dddef4339ad98c53db01a4ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3392a381c1403cbeb9451a15b742e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9051d423f34392b0613bac36ca95e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸: DistilBertForQuestionAnswering\n",
      "ëª¨ë¸ ì´ë¦„ í˜¹ì€ ê²½ë¡œ: distilbert/distilbert-base-cased-distilled-squad\n",
      "ì‚¬ìš© ì¤‘ì¸ í† í¬ë‚˜ì´ì €: DistilBertTokenizerFast\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "# 'question-answering' íŒŒì´í”„ë¼ì¸ì„ ë¡œë“œí•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ëŠ”\n",
    "# ì‚¬ì „ì— í•™ìŠµëœ QA ëª¨ë¸(ê¸°ë³¸ê°’: 'distilbert-base-cased-distilled-squad')ì„ ê¸°ë³¸ ì‚¬ìš©.\n",
    "# ì¸ìë¡œ model, tokenizer, device ë“±ì„ ì§ì ‘ ì„¤ì • ê°€ëŠ¥\n",
    "qa_pipeline = pipeline('question-answering')\n",
    "\n",
    "# íŒŒì´í”„ë¼ì¸ ê°ì²´ì—ì„œ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ì ‘ê·¼í•˜ê¸°\n",
    "model = qa_pipeline.model\n",
    "tokenizer = qa_pipeline.tokenizer\n",
    "\n",
    "print(\"ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸:\", model.__class__.__name__)\n",
    "print(\"ëª¨ë¸ ì´ë¦„ í˜¹ì€ ê²½ë¡œ:\", model.name_or_path)\n",
    "print(\"ì‚¬ìš© ì¤‘ì¸ í† í¬ë‚˜ì´ì €:\", tokenizer.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 253,
     "status": "ok",
     "timestamp": 1734414631518,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "H2-N5yRJ7K6i",
    "outputId": "4fdecb75-d111-47a4-c702-6acd27c49d99"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/question_answering.py:391: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.8067139387130737, 'start': 14, 'end': 17, 'answer': 'NLP'}\n"
     ]
    }
   ],
   "source": [
    "result = qa_pipeline({\n",
    "    'context': \"Hugging FaceëŠ” NLP ë¶„ì•¼ì—ì„œ ë§¤ìš° ìœ ëª…í•œ ì˜¤í”ˆì†ŒìŠ¤ ì»¤ë®¤ë‹ˆí‹°ì´ì ê¸°ì—…ì´ë‹¤.\",\n",
    "    'question': \"Hugging FaceëŠ” ì–´ë–¤ ë¶„ì•¼ì—ì„œ ìœ ëª…í•œê°€?\"\n",
    "})\n",
    "print(result)\n",
    "# ê²°ê³¼ ì˜ˆì‹œ:\n",
    "# {'score(ì‹ ë¢°ë„)': 0.95, 'start(ì‹œì‘ ì¸ë±ìŠ¤)': 18, 'end(ë ì¸ë±ìŠ¤)': 21, 'answer(ì •ë‹µ í…ìŠ¤íŠ¸)': 'NLP'}\n",
    "# ìœ„ ì˜ˆì œì—ì„œ, contextì™€ questionì„ dict í˜•íƒœë¡œ ì „ë‹¬í•˜ë©´ íŒŒì´í”„ë¼ì¸ì´ ë‚´ë¶€ì ìœ¼ë¡œ\n",
    "# í† í°í™” â†’ ëª¨ë¸ì¶”ë¡  â†’ ë‹µë³€ ì¶”ì¶œì„ ì§„í–‰í•œ ë’¤ answerë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAB8h4In7d1k"
   },
   "source": [
    "### íŒŒì´í”„ë¼ì¸ ìƒì„± ì‹œ ì›í•˜ëŠ” ëª¨ë¸ ì§€ì •í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264,
     "referenced_widgets": [
      "944778b463ab46a0b5d6b8532af7b5c1",
      "2697f16ebddd42b8ad8d4a70fa48c13a",
      "74959109664a430a82d871ceba6db27c",
      "01fdabe9ce6247839d3faa82b54f1e29",
      "0ddb09a4f37949b09302642a9378faa6",
      "f70168e25edc4a6e85f112fce0a209c5",
      "206bbcb12f6b4f5799d8acbb8bef424c",
      "f13ae4bfd4d44654bd50f76191b53121",
      "90ad7bd79a3f4a1589aaf5ad9630cf7f",
      "a995b5f5cd504ff4814e37190f147ebf",
      "3b75c6bd23a44ee791167a9352a3a150",
      "531ab124c8dc4b40af7442b78dc3ac1f",
      "2ff09fe853d54fa484abeb9864e90ba1",
      "108d9abd930d4437bd72ea8bee9c906e",
      "9a509871ed6f4180ac5392dedf52c88e",
      "1bd85f3a4b544dc685fed90252b30b4d",
      "b610fa7d5a304345a17be8142298c584",
      "c705b0a71cc9477cbf887fb13c99d7c1",
      "d6ab102c156a4ef48f36e77f162b5251",
      "d12c918459fc4949b184edc3ed6795df",
      "fa6266b2cdd6451790cf9e821d4a40b0",
      "bbf9a111b75941fdbc5e8dc6d249060b",
      "72ff355380264721a96b53b32663f65d",
      "18ec203fae624883b3c246e32d62cc4d",
      "91053c1591894cc4b426ed6d90fc0521",
      "9982a1bc65f440aa8abfc1809699c812",
      "2fc0cc36f88742eaa69b75bbba1237a5",
      "244816439ef74a9c9ca828fa14d8a941",
      "27b7fddcdbbf4fd7b211f6ff7c98f153",
      "3c2b4f07f2084982aa940a067aab2097",
      "16e0a2f74aed42668feab156fe447be7",
      "788f7cdfbd8d4aa1ac5fc1dce84e9f15",
      "f412f54a4bc3413ca0ed0ad09ce22640",
      "8fb7438de7b84e26bc88c299a3ccf709",
      "a40d4a1571c449d89ddd2a1022d91e86",
      "7a94bc82ebe545d8996cae957e1aca02",
      "af60e8945e4e4952851cc65fc31516e7",
      "7ebeb838b8b54c5ab0375989ad1fc0d0",
      "857b471cf8d648d69aa756a07e95c373",
      "acd7bef237674e9cb53edca1b466d1ed",
      "d04c3e051b0b4609a89fdeb8d70c889a",
      "ace83eeea5ed4903b76c01d1ff8ebf51",
      "05bdf1eccd7d4c299543b66cc09487b6",
      "ca9a666990b74a948f8cd64f300fa448",
      "e36ae3df6ebc422f84f4afe39c7c8bd7",
      "af01d83566be4a1f89d2875a4e2d8c7a",
      "ccb411c2aac1401b86e4201ad94e3151",
      "d869ab046fb245b6b5383af22576eba9",
      "f9c3a24214d34445b7fa0b7b417b47ba",
      "2315bf1fe6834c889cc4c80987b9bc1c",
      "dad0fbc2a676476abc0c5433132f1603",
      "e39844a355704d72877d1fea5adc0bdc",
      "ae39a667b32a4679a39c6caaeb701d3e",
      "6d8b2c135a6843d9a73ddfe118f4c046",
      "a0e50bd5b87542f4b98620684251fe29",
      "1c557cc77d9e4f919999abcf944337f4",
      "f176823114ef4a839e6afe2fee03a4ba",
      "f54b8cac3da2490a968bdee3f4008f50",
      "10f202bc7d4245f28a0b1957c9f7499e",
      "6904f70d45584635ad4289961cf7cb74",
      "79ac26008d8a45c585a9221c8281c434",
      "ae3fe7f8cd864069883264869e0bd175",
      "94ce86d5a2f24ed485b837ede8576624",
      "5f638bbf97a547429195387af989d008",
      "a8b57eda58e249fca61337695a167325",
      "b9e6ae409ef944f68b14f7162c66f73a"
     ]
    },
    "executionInfo": {
     "elapsed": 5120,
     "status": "ok",
     "timestamp": 1734414636636,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "OxQTYI927hTl",
    "outputId": "e9ffe902-18fd-47fe-9eda-f24772a29dba"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944778b463ab46a0b5d6b8532af7b5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531ab124c8dc4b40af7442b78dc3ac1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ff355380264721a96b53b32663f65d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb7438de7b84e26bc88c299a3ccf709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36ae3df6ebc422f84f4afe39c7c8bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c557cc77d9e4f919999abcf944337f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸: RobertaForQuestionAnswering\n",
      "ëª¨ë¸ ì´ë¦„ í˜¹ì€ ê²½ë¡œ: deepset/roberta-base-squad2\n"
     ]
    }
   ],
   "source": [
    "# íŠ¹ì • ëª¨ë¸ ì´ë¦„ ì§€ì •(ì˜ˆ: 'bert-base-uncased'ë¥¼ QA ëª¨ë¸ë¡œ í™œìš©)\n",
    "# ë‹¨, \"question-answering\" íƒœìŠ¤í¬ëŠ” SQuAD ë“± QAìš©ìœ¼ë¡œ íŒŒì¸íŠœë‹ëœ ëª¨ë¸ì„ ì“°ëŠ” ê²ƒì´ ì¼ë°˜ì ì´ë¯€ë¡œ\n",
    "# ê¸°ë³¸ BERT ëª¨ë¸ì„ ë°”ë¡œ ì“°ë©´ ì„±ëŠ¥ì´ ë‚®ì„ ìˆ˜ ìˆìŒ.\n",
    "# ì—¬ê¸°ì„œëŠ” QA íƒœìŠ¤í¬ìš©ìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ ì˜ˆë¥¼ ë“¤ì–´ë´„: 'deepset/roberta-base-squad2'\n",
    "qa_pipeline_custom = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=\"deepset/roberta-base-squad2\",\n",
    "    tokenizer=\"deepset/roberta-base-squad2\"\n",
    ")\n",
    "\n",
    "print(\"ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸:\", qa_pipeline_custom.model.__class__.__name__)\n",
    "print(\"ëª¨ë¸ ì´ë¦„ í˜¹ì€ ê²½ë¡œ:\", qa_pipeline_custom.model.name_or_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aak0Gyba0IbZ"
   },
   "source": [
    "## 5. íŒŒì´í”„ë¼ì¸ ë™ì‘ íë¦„ ì´í•´\n",
    "1. **ë¬¸ì„œ ì…ë ¥**: ì‚¬ìš©ìê°€ ì§ˆì˜ì‘ë‹µ ëŒ€ìƒì´ ë˜ëŠ” í…ìŠ¤íŠ¸(ì»¨í…ìŠ¤íŠ¸)ì™€ ì§ˆë¬¸ì„ ì…ë ¥.\n",
    "2. **í† í°í™”**: contextì™€ questionì„ í•©ì³ ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” í† í° í˜•íƒœë¡œ ë³€í™˜.\n",
    "3. **ëª¨ë¸ ì¶”ë¡ **: ì‚¬ì „ í•™ìŠµëœ QA ëª¨ë¸(BERT ê¸°ë°˜ ë“±)ì„ í†µí•´ questionê³¼ contextë¥¼ í•¨ê»˜ ì…ë ¥ë°›ì•„ answer spanì„ ì˜ˆì¸¡.\n",
    "4. **ë‹µë³€ ì¶”ì¶œ**: ì˜ˆì¸¡ëœ ì‹œì‘ í† í°ê³¼ ì¢…ë£Œ í† í° ìœ„ì¹˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ context ë¬¸ì„œì—ì„œ í•´ë‹¹ ë²”ìœ„ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ ìµœì¢… ë‹µë³€ìœ¼ë¡œ ì œê³µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VEB7ETA0IY8"
   },
   "source": [
    "## 6. ê°„ë‹¨í•œ ì§ˆì˜ì‘ë‹µ ë´‡ íŒŒì¸íŠœë‹ ì‹¤ìŠµ\n",
    "ì§§ì€ ìœ„í‚¤í”¼ë””ì•„ ë¬¸ì„œë¥¼ í•˜ë‚˜ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
    "ì˜ˆ: ìœ„í‚¤í”¼ë””ì•„ì˜ \"Python(ì–¸ì–´)\" ë¬¸ì„œ ì¼ë¶€ ë°œì·Œ.\n",
    "ì‚¬ìš©ìë¡œë¶€í„° ì§ˆë¬¸ì„ ì…ë ¥ë°›ê³ , QA pipelineì— í•´ë‹¹ ì§ˆë¬¸ê³¼ ë¬¸ì„œë¥¼ ë„£ì–´ ëª¨ë¸ì˜ ë‹µë³€ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "ë¬¸ì„œë¥¼ ë°”ê¾¸ê±°ë‚˜ ì§ˆë¬¸ì„ ë°”ê¿”ê°€ë©° ëª¨ë¸ ë°˜ì‘ì„ ì‚´í´ë³´ê³ , ì •í™•í•˜ì§€ ì•Šì€ ë‹µë³€ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í†µí•´ ëª¨ë¸ì˜ í•œê³„ì ì„ íŒŒì•…í•´ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1734414636944,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "GF9Di_xq0mGR",
    "outputId": "9dac7817-ac66-4835-f693-bca589f334da"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì§ˆë¬¸: Pythonì€ ëˆ„ê°€ ë°œí‘œí–ˆëŠ”ê°€?\n",
      "ë‹µë³€: Guido van Rossum\n",
      "ì ìˆ˜(ì •í™•ë„ ì¶”ì •ì¹˜): 0.41587844491004944\n",
      "ì§ˆë¬¸: Pythonì€ ì–¸ì œ ë°œí‘œë˜ì—ˆëŠ”ê°€?\n",
      "ë‹µë³€: Guido van Rossum (ì •í™•ë„: 0.41587844491004944 )\n",
      "ì§ˆë¬¸: Pythonì€ ì–´ëŠ í–‰ì„±ì—ì„œ ìœ ë˜í–ˆëŠ”ê°€?\n",
      "ë‹µë³€: Guido van Rossum (ì •í™•ë„: 0.3983064591884613 )\n"
     ]
    }
   ],
   "source": [
    "# Hugging Faceì—ì„œ ì œê³µí•˜ëŠ” Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.\n",
    "# Transformers: ì‚¬ì „ í•™ìŠµëœ NLP ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë“± ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "from transformers import pipeline\n",
    "\n",
    "# question-answering íŒŒì´í”„ë¼ì¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "# pipeline('question-answering')ì€ ê¸°ë³¸ì ìœ¼ë¡œ QAë¥¼ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ìë™ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "qa_pipeline = pipeline('question-answering')\n",
    "\n",
    "# ì•„ë˜ contextëŠ” ìœ„í‚¤í”¼ë””ì•„ì˜ Python ì–¸ì–´ í•­ëª© ì¤‘ ì¼ë¶€ë¥¼ ë°œì·Œí•œ ì˜ˆì‹œì…ë‹ˆë‹¤.\n",
    "# (ì¶œì²˜: Wikipedia \"Python (programming language)\" ë¬¸ì„œ ì¼ë¶€, ê°€ìƒì˜ ì˜ˆì‹œ)\n",
    "context = \"\"\"\n",
    "Pythonì€ 1991ë…„ ê·€ë„ ë°˜ ë¡œì„¬(Guido van Rossum)ì´ ë°œí‘œí•œ ì¸í„°í”„ë¦¬í„° ë°©ì‹ì˜ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë¡œ,\n",
    "ì½”ë“œ ê°€ë…ì„±ì´ ìš°ìˆ˜í•˜ê³  ë‹¤ì–‘í•œ í”„ë¡œê·¸ë˜ë° íŒ¨ëŸ¬ë‹¤ì„ì„ ì§€ì›í•œë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "# í•¨ìˆ˜ ì˜ˆì œ: ì§ˆì˜ì‘ë‹µì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜\n",
    "# ì…ë ¥: (context: str, question: str)\n",
    "# ì¶œë ¥: dict í˜•íƒœë¡œ {'answer': str, 'score': float, 'start': int, 'end': int} í˜•ì‹ì˜ ë‹µë³€ ì •ë³´\n",
    "def answer_question(context, question):\n",
    "    # íŒŒì´í”„ë¼ì¸ì— contextì™€ questionì„ dict í˜•íƒœë¡œ ì „ë‹¬\n",
    "    result = qa_pipeline({\n",
    "        'context': context,\n",
    "        'question': question\n",
    "    })\n",
    "    return result\n",
    "\n",
    "# ì˜ˆì‹œ ì§ˆì˜ì‘ë‹µ ìˆ˜í–‰\n",
    "# question: \"Pythonì€ ëˆ„ê°€ ë°œí‘œí–ˆëŠ”ê°€?\"\n",
    "# ê¸°ëŒ€ë˜ëŠ” ë‹µë³€: \"ê·€ë„ ë°˜ ë¡œì„¬(Guido van Rossum)\"\n",
    "question = \"Pythonì€ ëˆ„ê°€ ë°œí‘œí–ˆëŠ”ê°€?\"\n",
    "result = answer_question(context, question)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"ì§ˆë¬¸:\", question)\n",
    "print(\"ë‹µë³€:\", result['answer'])\n",
    "print(\"ì ìˆ˜(ì •í™•ë„ ì¶”ì •ì¹˜):\", result['score'])\n",
    "\n",
    "# ë‹¤ë¥¸ ì§ˆë¬¸ ì‹œë„\n",
    "# question: \"Pythonì€ ì–¸ì œ ë°œí‘œë˜ì—ˆëŠ”ê°€?\"\n",
    "# ê¸°ëŒ€ ë‹µë³€: \"1991ë…„\"\n",
    "question = \"Pythonì€ ì–¸ì œ ë°œí‘œë˜ì—ˆëŠ”ê°€?\"\n",
    "result = answer_question(context, question)\n",
    "print(\"ì§ˆë¬¸:\", question)\n",
    "print(\"ë‹µë³€:\", result['answer'], \"(ì •í™•ë„:\", result['score'], \")\")\n",
    "\n",
    "# ëª¨ë¸ í•œê³„ì  ê´€ì°°ì„ ìœ„í•œ ì—‰ëš±í•œ ì§ˆë¬¸\n",
    "# contextì— ì—†ëŠ” ì •ë³´ ì§ˆë¬¸: \"Pythonì€ ì–´ëŠ í–‰ì„±ì—ì„œ ìœ ë˜í–ˆëŠ”ê°€?\"\n",
    "# ì´ ê²½ìš° ë¬¸ë§¥ì— ì—†ëŠ” ì •ë³´ì´ë¯€ë¡œ ë‹µë³€ì´ ì–´ìƒ‰í•˜ê±°ë‚˜ ë¬¸ë§¥ê³¼ ë¬´ê´€í•˜ê²Œ ì¶”ì¶œë  ìˆ˜ ìˆìŒ.\n",
    "question = \"Pythonì€ ì–´ëŠ í–‰ì„±ì—ì„œ ìœ ë˜í–ˆëŠ”ê°€?\"\n",
    "result = answer_question(context, question)\n",
    "print(\"ì§ˆë¬¸:\", question)\n",
    "print(\"ë‹µë³€:\", result['answer'], \"(ì •í™•ë„:\", result['score'], \")\")\n",
    "\n",
    "# ì´ì²˜ëŸ¼ ì—†ëŠ” ì •ë³´ì— ëŒ€í•œ ì§ˆë¬¸ì´ë‚˜ ëª¨í˜¸í•œ ì§ˆë¬¸, ì‚¬ì „í•™ìŠµ ë°ì´í„°ì™€ ê´€ë ¨ì´ ì ì–¸ ì–¸ì–´ì— ëŒ€í•´ ëª¨ë¸ì´ ë¶€ì •í™•í•œ ë‹µë³€ì„ ë‚´ë†“ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdvYpOIe0DsW"
   },
   "source": [
    "## 7. ëª¨ë¸ í•œê³„ì  ë° ì—ëŸ¬ ì¼€ì´ìŠ¤\n",
    "ë¬¸ì„œ ì•ˆì— ì—†ëŠ” ì •ë³´ì— ëŒ€í•œ ì§ˆë¬¸ì„ í•˜ë©´, ì—‰ëš±í•œ ë‹µë³€ì„ í•˜ê±°ë‚˜ ìµœì ì˜ ë‹µë³€ì„ ì°¾ì§€ ëª»í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "ë¬¸ì¥ì´ ì• ë§¤í•˜ê±°ë‚˜ ì¤‘ì˜ì ì´ë©´ ëª¨ë¸ì´ ë¬¸ë§¥ íŒŒì•…ì„ ì œëŒ€ë¡œ í•˜ì§€ ëª»í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "ì „ë¬¸ìš©ì–´, ì½”ë“œ ì˜ˆì‹œ, ìˆ«ì ë“± íŠ¹ì • íƒ€ì…ì˜ ì •ë³´ì— ëŒ€í•´ ì •í™•ë„ê°€ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "buN-ktKm60Rv"
   },
   "source": [
    "### ê°„ë‹¨í•œ ë°ì´í„°ë¡œ íŒŒì¸íŠœë‹(Fine-tuning)í•˜ê¸°\n",
    "\n",
    "- Hugging Face TransformersëŠ” íŒŒì¸íŠœë‹ì„ ìœ„í•´ Trainer APIë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
    "- ë‹¤ìŒì€ SQuAD ê°™ì€ ì§ˆì˜ì‘ë‹µ ë°ì´í„°ì…‹ ì¼ë¶€ë¥¼ ì´ìš©í•´ íŒŒì¸íŠœë‹í•˜ëŠ” ê°„ë‹¨í•œ ì˜ˆì‹œ íë¦„ì…ë‹ˆë‹¤.\n",
    "\n",
    "**íŒŒì¸íŠœë‹ ê°œë…**\n",
    "- ì´ë¯¸ QA íƒœìŠ¤í¬ë¡œ ì‚¬ì „í•™ìŠµ(fine-tuned)ëœ ëª¨ë¸ì„ ë” ì‘ì€ ìƒˆë¡œìš´ ë°ì´í„°ì— ë§ì¶° ì¶”ê°€ í›ˆë ¨í•˜ëŠ” ê³¼ì •.\n",
    "- ì˜ˆì‹œ: íŠ¹ì • ë„ë©”ì¸(ì˜ë£Œ, ë²•ë¥ )ì— íŠ¹í™”ëœ ë°ì´í„°ë¡œ íŒŒì¸íŠœë‹í•˜ì—¬ í•´ë‹¹ ë„ë©”ì¸ ì§ˆë¬¸ì— ë” ì •í™•íˆ ë‹µí•˜ë„ë¡ í•¨.\n",
    "\n",
    "**ì‹¤ìŠµ**: QA ëª¨ë¸ íŒŒì¸íŠœë‹(ìš”ì•½ëœ íë¦„)\n",
    "ë°ì´í„° ì¤€ë¹„\n",
    "- context, question, answers(ì •ë‹µ ë²”ìœ„ë¥¼ ì§€ì •í•œ í˜•íƒœ)ë¡œ êµ¬ì„±ëœ JSON ë˜ëŠ” CSV í˜•íƒœ ë°ì´í„° ì¤€ë¹„.\n",
    "- SQuAD í¬ë§· ì˜ˆì‹œ:\n",
    "```{\n",
    "  \"data\": [\n",
    "    {\n",
    "      \"title\": \"Example Title\",\n",
    "      \"paragraphs\": [\n",
    "        {\n",
    "          \"context\": \"ì—¬ê¸°ëŠ” íŒŒì¸íŠœë‹ìš© ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\",\n",
    "          \"qas\": [\n",
    "            {\n",
    "              \"id\": \"1\",\n",
    "              \"question\": \"ì—¬ê¸°ëŠ” ë¬´ì—‡ì„ ìœ„í•œ ë¬¸ì„œì¸ê°€?\",\n",
    "              \"answers\": [\n",
    "                {\n",
    "                  \"text\": \"íŒŒì¸íŠœë‹ìš© ë¬¸ì„œ\",\n",
    "                  \"answer_start\": 4\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "noC1O3cg-5Vw"
   },
   "source": [
    "ì•„ë˜ ì½”ë“œëŠ” ì„¤ëª…ì„ ìœ„í•œ ì˜ˆì‹œì´ë©°, ì‹¤ì œë¡œëŠ” ë‹¤ì–‘í•œ ì„¤ì •(í•˜ì´í¼íŒŒë¼ë¯¸í„°, ë°ì´í„°ì…‹ ê²½ë¡œ, ëª¨ë¸ ê²½ë¡œ) ì¡°ì •ì´ í•„ìš”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpwrWCnkJcF4"
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434,
     "referenced_widgets": [
      "77b84912061c42dabdd1ad082b6bff5e",
      "a4a7f16072644d1881601bbcb2258148",
      "ae254beeaa544333a39943e5ab36a309",
      "8b3bdc89cf3e48c083b3a7ebdb29b544",
      "888f47812d7942e6a7a03ea139bb3e77",
      "ca2531b2ac05480facefceeb5dd6c9c7",
      "b4314446001a4d93b5d5f30eea8d99eb",
      "f17f4d923a004b52bba0ec0d99fbc189",
      "50543f9a19b946a4bfdabb8d92e884e5",
      "14f6f0dbc1f9491eb77839ddece22072",
      "370f5ee7a694466095af46390d76c612",
      "0e2ac99f802144aead1a54d56bb8f1e7",
      "59224b5d02a4493a9d5c1aee32335041",
      "85d36e999d9e405f9b9c6ea823ba3037",
      "72e663083b4146b091ad7ea65cc1ad1c",
      "eb6b856420fd46d9b0ca1e0437223775",
      "35d9ad7768fe450f885221cd1a6e7b71",
      "fd1419b06b964f98893386781c5fcb12",
      "d2efdcb382cc4726b84b659825155ade",
      "abaa275376bc4704bb973be17208bc34",
      "a699358920a74bb8811c8e539ed3e8ca",
      "7da11415768b4bb096f861e62b7c2c64",
      "c1785aaa4ef14426856898b7cf27b640",
      "46f934b7682346bfaf62a292db82bd98",
      "bd1bf340c2594f6c866adb648571773e",
      "9abf522e62054b14aef06f2460fbc106",
      "ebb6ae9d9ed048a9833a4a4cd33a3a60",
      "23caf1f7456a44d9a074f71537791675",
      "2e4beed6c44340fd8ba049b0792730c6",
      "28513127b35443d08ccd4f2dfafd3ccc",
      "ae46a209c3a7449c903e65e952ad7fca",
      "eaf291015635496192597c093114eb9b",
      "13937821e3ec48e19ed12d1d54ea7a5d",
      "d96cdfcbfe1640bd9c4fe6672ec72491",
      "c58ea0bf26244f0892f0ccc73c8bede3",
      "d321ef4d0df2428291d38e093c24fc2e",
      "a30110bf702640bca9fb1b4a2a6f6109",
      "023d3a4b115b44428417d8f0e08b6004",
      "fe50e993881546348be15796bde14c56",
      "a042d298414940048261ca9cf22baee1",
      "88dbab012a9e46c0b2e184aad9a392d9",
      "2af0be7c90ce4b25892d3b6033a11366",
      "def97e979445449fbae0d97de47579b0",
      "ad8a7e46aa9d457c84db576e1ef0d52e",
      "cd61eff83c96454984d338ded2fef306",
      "54c381ec014e476ea92cf72335a86757",
      "c0c05b4baaf94d8b832d9879eeeb9b5c",
      "20e652163df347aba5c5d5befd144ddc",
      "b939860ac9bc4ba49a9db35a38f52882",
      "75ebc69c055b4f6dbac0bd4e9951207e",
      "696fb3e488284cd5a962e9dd1ec21653",
      "18dc5593a8e24d65ace2239217d9a298",
      "ec87c8cf8cad4b61886ee11d7d6fc508",
      "8038291e2ff14f17bd46e4ea6a7b008e",
      "25870e63fd4f4b2dbed6cb5087b901f6",
      "2e00e44cfa2e41aab639dbbb4d025d92",
      "8e547e6f7132430db719f759e9aff8cb",
      "f63c411436364483abfdfa92dceb6d83",
      "9a8c6654819b49c3af51186d1965f528",
      "c02388a952ae492a8759f75f646bd10c",
      "cfb61d22e0bb4ad388e6c66f2fe87aaf",
      "c448ac34412240e99ee4a46e35b8190c",
      "8661dc894eab47268af239da46741e93",
      "247e5ea419a04a8dab6dcf6b658076ea",
      "5c35772bb1fa429588083ab298814a60",
      "a11598576af94323ab53dbb5e49c4c85",
      "a55ff8aa54e34137be611105a21474d3",
      "4bca3918ace945659379a05cf42fc4f5",
      "f3a0b71c061a42209bf119727e9e0d81",
      "f707f4c7cb6c4119bca09be136023eff",
      "a6b884aa992344aaa884d402b8337417",
      "b9c77b5de7cf488b884a5c169b1ef017",
      "0158a8406db446cfa3b61e7c0018d2ec",
      "fa45f1ec74cf4e8ba6a25dffc069ad86",
      "ff93ee676f5f4470ac3ff4e21531095e",
      "9230569bbdc54decb6cb4b966f21f284",
      "8a1a6f08516648c5b29c58e4ca796e67",
      "5f7ce392c1b64b828c5efeba8f100424",
      "2a06490ac7fa4c2f85350ff6e933f524",
      "49e9dc51e4df4ee8ac7aaca103708afe",
      "448684bf41e94cc187e0cbd9fa474863",
      "31f552ce3f2442829c66b1e9bf72ac51",
      "3360823659dd49f888017712fb26217c",
      "1c5a9706142a465c979d510d67fe3d61",
      "5bc2e42c8d8b415b96815fab65beb2df",
      "227883cf677c4eff916fa665385862ce",
      "fa3062223cea4e9da9884f2528dd5430",
      "d55cfe0cfc9f4d8d818c2c6c314333b4",
      "c3363797240647b0920dc43c9147fc51",
      "67f5526c0bef4bc994fd1e1c4a6483b6",
      "bbf8a168cd47459aa2a676e454f13d65",
      "a65d46ec6f4b48789e3ab57ce19bd298",
      "468a8695daf0405b9c2252e4b5aca2f0",
      "fcc9b4ac12714265b46e576e9a1da8b6",
      "c93194b88cd94f84b4234259deb8a284",
      "3609fd1faf3b4a82951efbda9ba8d70f",
      "173a35dd4571465cbe43ff300f9c560c",
      "ce405710a833409284e6e11c51c6ddea",
      "6821627266b34c00be54ae40489a8aa1"
     ]
    },
    "executionInfo": {
     "elapsed": 59407,
     "status": "ok",
     "timestamp": 1734418962800,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "9w-zGNJp1V6B",
    "outputId": "a90bd1a0-aece-45df-bd67-6362150d117f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b84912061c42dabdd1ad082b6bff5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/6.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e2ac99f802144aead1a54d56bb8f1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/11.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1785aaa4ef14426856898b7cf27b640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96cdfcbfe1640bd9c4fe6672ec72491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/60407 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd61eff83c96454984d338ded2fef306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/5774 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e00e44cfa2e41aab639dbbb4d025d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55ff8aa54e34137be611105a21474d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/591 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7ce392c1b64b828c5efeba8f100424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/263k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3363797240647b0920dc43c9147fc51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# datasets: ë‹¤ì–‘í•œ NLP ë°ì´í„°ì…‹ ë¡œë“œ ë° ì²˜ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "# transformers: Hugging Face Transformersë¡œ ëª¨ë¸, í† í¬ë‚˜ì´ì €, Trainer ë“± ì‚¬ìš©\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "\n",
    "# 1) ë°ì´í„° ë¡œë“œ: KorQuAD (https://huggingface.co/datasets/KorQuAD/squad_kor_v1)\n",
    "# KorQuADëŠ” í•œêµ­ì–´ ê¸°ê³„ë…í•´(MRC) ë°ì´í„°ì…‹ìœ¼ë¡œ, SQuAD í˜•ì‹ì„ ë”°ë¦…ë‹ˆë‹¤.\n",
    "# ì „ì²´ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ë©´ ìš©ëŸ‰ì´ í¬ê¸° ë•Œë¬¸ì— ì—¬ê¸°ì„œëŠ” 'validation' splitë§Œ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "val_data = load_dataset('KorQuAD/squad_kor_v1', split='validation')\n",
    "\n",
    "# 2) ë°ì´í„° ë¶„í• : validation ë°ì´í„°ë¥¼ 8:2 ë¹„ìœ¨ë¡œ trainê³¼ testë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.\n",
    "# train_test_split í•¨ìˆ˜ëŠ” Dataset ê°ì²´ë¥¼ ë‚˜ëˆ„ì–´ DatasetDict í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "split_data = val_data.train_test_split(test_size=0.2)\n",
    "\n",
    "# ë¶„í• ëœ ë°ì´í„°ì…‹ì„ ê°ê° ë³€ìˆ˜ì— ì €ì¥:\n",
    "train_dataset = split_data['train']  # ì „ì²´ ë°ì´í„°ì˜ 80%ë¥¼ í›ˆë ¨ìš©ìœ¼ë¡œ ì‚¬ìš©.\n",
    "valid_dataset = split_data['test']   # ë‚˜ë¨¸ì§€ 20%ë¥¼ ê²€ì¦ìš©ìœ¼ë¡œ ì‚¬ìš©.\n",
    "\n",
    "# 3) KoELECTRA ê¸°ë°˜ KorQuAD ëª¨ë¸ì˜ í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "# monologg/koelectra-base-v3-finetuned-korquad: KoELECTRA ëª¨ë¸ì„ KorQuAD ë°ì´í„°ì…‹ìœ¼ë¡œ ë¯¸ì„¸ ì¡°ì •í•œ ëª¨ë¸ì…ë‹ˆë‹¤.\n",
    "# AutoTokenizerëŠ” í•´ë‹¹ ëª¨ë¸ì˜ í† í¬ë‚˜ì´ì €ë¥¼ ìë™ìœ¼ë¡œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"monologg/koelectra-base-v3-finetuned-korquad\")\n",
    "\n",
    "# 4) ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜: SQuAD í˜•ì‹ì— ë§ëŠ” ë°ì´í„° ì „ì²˜ë¦¬\n",
    "# ì´ í•¨ìˆ˜ëŠ” ê° ë°ì´í„°ì…‹ ì˜ˆì œì˜ ì§ˆë¬¸(question), ë¬¸ë§¥(context), ì •ë‹µ(answers)ì„ í† í¬ë‚˜ì´ì§•í•˜ê³ ,\n",
    "# ëª¨ë¸ì´ í•™ìŠµí•  ìˆ˜ ìˆë„ë¡ start_positionsì™€ end_positionsë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "\n",
    "def preprocess_function(data):\n",
    "    \"\"\"\n",
    "    ë°ì´í„°ì…‹ì„ ëª¨ë¸ ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "    ì§ˆë¬¸ê³¼ ë¬¸ë§¥ì„ í† í¬ë‚˜ì´ì¦ˆí•˜ê³  ì •ë‹µì˜ ì‹œì‘/ë ìœ„ì¹˜ë¥¼ ê³„ì‚°í•˜ì—¬ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    tokenized = tokenizer(\n",
    "        data[\"question\"],        # ì§ˆë¬¸ í…ìŠ¤íŠ¸\n",
    "        data[\"context\"],         # ë¬¸ë§¥ í…ìŠ¤íŠ¸\n",
    "        truncation=True,         # ìµœëŒ€ ê¸¸ì´ë¥¼ ì´ˆê³¼í•˜ë©´ ë¬¸ë§¥ì„ ì˜ë¼ëƒ„\n",
    "        padding='max_length',    # ìµœëŒ€ ê¸¸ì´ì— ë§ê²Œ íŒ¨ë”© ì¶”ê°€\n",
    "        max_length=384,          # ìµœëŒ€ í† í° ê¸¸ì´ (ì¼ë°˜ì ìœ¼ë¡œ 384 ì‚¬ìš©)\n",
    "        return_offsets_mapping=True  # ê° í† í°ì˜ ì›ë³¸ í…ìŠ¤íŠ¸ ë‚´ ì‹œì‘/ë ìœ„ì¹˜ë¥¼ ë§¤í•‘\n",
    "    )\n",
    "\n",
    "    # 4-2. ì •ë‹µì˜ ì‹œì‘(start_positions)ê³¼ ë(end_positions) ì¸ë±ìŠ¤ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    # 4-3. ê° ì˜ˆì œì— ëŒ€í•´ í† í°í™”ëœ ì˜¤í”„ì…‹ê³¼ ì›ë³¸ ì •ë‹µ ìœ„ì¹˜ë¥¼ ë¹„êµí•˜ì—¬ í† í° ì¸ë±ìŠ¤ ê³„ì‚°\n",
    "    for i, offsets in enumerate(tokenized[\"offset_mapping\"]):\n",
    "        # KorQuAD v1 ë°ì´í„°ì˜ answers êµ¬ì¡°:\n",
    "        # {\"text\": [ì •ë‹µ ë¬¸ìì—´], \"answer_start\": [ì •ë‹µì˜ ì‹œì‘ ìœ„ì¹˜]}\n",
    "        answer_start = data[\"answers\"][i][\"answer_start\"][0]  # ì •ë‹µ ì‹œì‘ ìœ„ì¹˜ (ë¬¸ì„œ ë‚´ ìœ„ì¹˜)\n",
    "        answer_text = data[\"answers\"][i][\"text\"][0]           # ì •ë‹µ ë¬¸ìì—´\n",
    "        answer_end = answer_start + len(answer_text)          # ì •ë‹µ ë ìœ„ì¹˜\n",
    "\n",
    "        # ê° í† í°ì´ ë¬¸ë§¥ì— í•´ë‹¹í•˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” sequence_ids êµ¬í•˜ê¸°:\n",
    "        # sequence_idsëŠ” ê° í† í°ì´ question(0)ì¸ì§€ context(1)ì¸ì§€ êµ¬ë¶„í•©ë‹ˆë‹¤.\n",
    "        sequence_ids = tokenized.sequence_ids(i)  # ê° í† í°ì˜ sequence id (question/context êµ¬ë¶„)\n",
    "        context_start = sequence_ids.index(1)  # ë¬¸ë§¥(context)ì´ ì‹œì‘í•˜ëŠ” ì²« í† í°ì˜ ì¸ë±ìŠ¤\n",
    "        context_end = len(sequence_ids) - 1 - sequence_ids[::-1].index(1)  # ë¬¸ë§¥ì´ ëë‚˜ëŠ” ë§ˆì§€ë§‰ í† í°ì˜ ì¸ë±ìŠ¤\n",
    "\n",
    "        # ì •ë‹µ ì‹œì‘/ë ìœ„ì¹˜ë¥¼ í¬í•¨í•˜ëŠ” í† í°ì˜ ì¸ë±ìŠ¤ ì´ˆê¸°í™”\n",
    "        start_token_index = context_start\n",
    "        end_token_index = context_start\n",
    "\n",
    "        # ì˜¤í”„ì…‹ì„ ìˆœíšŒí•˜ë©° ì •ë‹µ ì‹œì‘ê³¼ ëì´ í¬í•¨ëœ í† í° ì¸ë±ìŠ¤ë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n",
    "        for idx, (offset_start, offset_end) in enumerate(offsets):\n",
    "            # ì •ë‹µ ì‹œì‘ ìœ„ì¹˜ê°€ í˜„ì¬ í† í°ì˜ ë²”ìœ„ì— í¬í•¨ë˜ë©´ start_token_index ì„¤ì •\n",
    "            if offset_start <= answer_start < offset_end:\n",
    "                start_token_index = idx\n",
    "            # ì •ë‹µ ë ìœ„ì¹˜ê°€ í˜„ì¬ í† í°ì˜ ë²”ìœ„ì— í¬í•¨ë˜ë©´ end_token_index ì„¤ì •\n",
    "            if offset_start < answer_end <= offset_end:\n",
    "                end_token_index = idx\n",
    "        # ì •ë‹µì˜ ì‹œì‘ê³¼ ë í† í° ì¸ë±ìŠ¤ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "        start_positions.append(start_token_index)\n",
    "        end_positions.append(end_token_index)\n",
    "\n",
    "    # 4-4. ëª¨ë¸ ì…ë ¥ì— í•„ìš”í•˜ì§€ ì•Šì€ \"offset_mapping\" í‚¤ë¥¼ ì œê±°í•©ë‹ˆë‹¤.\n",
    "    tokenized.pop(\"offset_mapping\", None)\n",
    "    # 4-5. ëª¨ë¸ í•™ìŠµì„ ìœ„í•´ start_positionsì™€ end_positionsë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "    tokenized[\"start_positions\"] = start_positions\n",
    "    tokenized[\"end_positions\"] = end_positions\n",
    "\n",
    "    # ìµœì¢…ì ìœ¼ë¡œ í† í¬ë‚˜ì´ì¦ˆëœ ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "81db2d7591444b0baa43e9dda9ac1550",
      "f23a807f4b8d4842acb0be73bd01b2a6",
      "4d88ff6dcafe4c47857abe1aa8c819b5",
      "c27462b30329403f875d26891b18df5f",
      "2173c5cae8e04013a600ee1adf2d4c5b",
      "2c107a76279f4e28a11b5c1675f6e9fe",
      "d80a5d549d63497c9b74a63a86c3eb51",
      "1dd6a372a0fc418f9981d0b1c317a4ab",
      "e0b52d655ff44fddaa11b69caca9ea57",
      "d890bcd606304351b147c39f6e317338",
      "a84e35a0bbe64d259610af186ce55822",
      "23a7ed64c7044e1ebdebd34e29f8133b",
      "a3c6ceb228fd467a9fc01defc90f822d",
      "eab84c94a9634833b2072374b90d8718",
      "8f382f19fa5d4f1e8450acf2ef13de50",
      "37af67a2899b4affb01a7c78ff87442e",
      "4daeace28afb4ffcb559d0bd9e0d4633",
      "96e58936ff0044a4931ded89511d420f",
      "612914e5313e40fd8322c035c4da8a1d",
      "113f407e034d417ea1b4e6fbfa1a47fa",
      "a0e26b727ce24010b2bb8744ccd82360",
      "791ba8b79efc405ea17b7fa8ffe7227a"
     ]
    },
    "executionInfo": {
     "elapsed": 12039,
     "status": "ok",
     "timestamp": 1734414661572,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "GsiBSIkizGwh",
    "outputId": "fdc56143-7995-48ef-83b6-f848fbaba0a2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81db2d7591444b0baa43e9dda9ac1550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4619 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a7ed64c7044e1ebdebd34e29f8133b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# map í•¨ìˆ˜ë¥¼ í†µí•´ ì‹¤ì œ í† í°í™” ì ìš©\n",
    "train_tokenized = train_dataset.map(preprocess_function, batched=True)\n",
    "valid_tokenized = valid_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1734414661572,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "iaOQCQYqlxv_",
    "outputId": "960b9acb-b14f-40ec-94c2-11b24c527e4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5ì›” 27ì¼, ì§€ë‚œ 4ì›” 29ì¼ ë‹¤ë¼ ì§€ì—­ì—ì„œ ë°˜ì •ë¶€ ì‹œìœ„ì— ì°¸ì—¬í–ˆë˜ 13ì‚´ ì†Œë…„ í•¨ì ì•Œí•˜í‹°ë¸Œ (Hamza Al-Khatib) ê°€ ê³ ë¬¸ í”ì ì´ ê°€ë“í•œ ì‹œì²´ë¡œ ì§‘ì— ëŒì•„ì˜¤ì, ì‹œë¦¬ì•„ì¸ë“¤ê³¼ êµ­ì œ ì‚¬íšŒì˜ ë¶„ë…¸ê°€ ë¹—ë°œì³¤ë‹¤. 5ì›” 29ì¼, í™ˆìŠ¤ ì£¼ì˜ íƒˆë¹„ì…°íì™€ ë¼ìŠ¤íƒ„ì—ì„œ ë°”ìƒ¤ë¥´ ì•Œì•„ì‚¬ë“œ ëŒ€í†µë ¹ì— ë°˜ëŒ€í•˜ëŠ” ì‹œìœ„ê°€ ë²Œì–´ì¡Œìœ¼ë©°, ì •ë¶€ì˜ íƒ±í¬ì™€ ì¤‘ê¸°ê´€ì´ì„ ë™ì›í•œ ìœ í˜ˆ ì§„ì••ìœ¼ë¡œ 11ëª…ì´ ì‚´í•´ë˜ê³ , ë¬´ìˆ˜í•œ ì‚¬ëŒë“¤ì´ ë¶€ìƒì„ ì…ì—ˆë‹¤. íƒˆë¹„ì…°íì™€ ë¼ìŠ¤íƒ„ ì´ì™¸ì—, ë‹¤ë¼, ë°”ë‹ˆì•¼ìŠ¤, íƒˆì¹¼ë¼í¬ì—ì„œë„ ë°˜ì •ë¶€ ì‹œìœ„ì— ëŒ€í•œ ìœ í˜ˆ ì§„ì••ì´ ê³„ì†ë˜ì—ˆë‹¤. 5ì›” 30ì¼, ë°˜ì •ë¶€ ì‹œìœ„ìë“¤ê³¼ ì •ë¶€êµ° ê°„ì˜ ì²« ë¬´ì¥ ì¶©ëŒì´ ì¼ì–´ë‚¬ìœ¼ë©° , ì‹œë¦¬ì•„ì˜ ì§‘ê¶Œë‹¹ ë°”íŠ¸ë‹¹ì€ ì „êµ­ë¯¼ëŒ€í™”ìœ„ì›íšŒë¥¼ êµ¬ì„±í•˜ì˜€ë‹¤.\n",
      "ë°˜ì •ë¶€ ì‹œìœ„ìë“¤ê³¼ ì •ë¶€êµ° ê°„ì˜ ì²« ë¬´ì¥ ì¶©ëŒì´ ì¼ì–´ë‚œ ë‚ ì§œëŠ” ì–¸ì œì¸ê°€?\n",
      "{'text': ['5ì›” 30ì¼'], 'answer_start': [291]}\n"
     ]
    }
   ],
   "source": [
    "# ê²°ê³¼ í™•ì¸\n",
    "print(valid_tokenized[0]['context'])  # ì›ë³¸ í…ìŠ¤íŠ¸\n",
    "print(valid_tokenized[0]['question'])\n",
    "print(valid_tokenized[0]['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452,
     "referenced_widgets": [
      "46993f496fef41afa2252d039989e32a",
      "4fee00fa5e4a4f1db186c49cafc894e0",
      "0f32d73796ee4ecf96aec7f825b3e484",
      "1da1455e8cd74ef484e55922c066d081",
      "8a662bbbe615434da060836ee8ebc542",
      "aaeef30e91b8428ab6490f286b50531c",
      "e0fe27efcbdc4634bcfb31aa94d629d7",
      "1112390a1c474f0bb1a92f931ad88c48",
      "71324d2a40b4471fa42a71a9b226f193",
      "9912dcb311ad421fb5874e47746be309",
      "cf4199c333b8417aba8cfe563ea3a3c4"
     ]
    },
    "executionInfo": {
     "elapsed": 805691,
     "status": "ok",
     "timestamp": 1734415467261,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "3C8YafjB_JHB",
    "outputId": "e7b27356-19cf-45ab-c586-6dc73d86ec47"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46993f496fef41afa2252d039989e32a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/449M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ğŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "<ipython-input-9-41efcc9e9c78>:16: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20241217_055251-7o0dvdtr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/minsukim/huggingface/runs/7o0dvdtr' target=\"_blank\">./qa_finetuned_model</a></strong> to <a href='https://wandb.ai/minsukim/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/minsukim/huggingface' target=\"_blank\">https://wandb.ai/minsukim/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/minsukim/huggingface/runs/7o0dvdtr' target=\"_blank\">https://wandb.ai/minsukim/huggingface/runs/7o0dvdtr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='290' max='290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [290/290 11:27, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=290, training_loss=0.41807542998215247, metrics={'train_runtime': 793.2282, 'train_samples_per_second': 11.646, 'train_steps_per_second': 0.366, 'total_flos': 1810394579045376.0, 'train_loss': 0.41807542998215247, 'epoch': 2.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ëª¨ë¸ ë¡œë“œ\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"monologg/koelectra-base-v3-finetuned-korquad\")\n",
    "\n",
    "# íŠ¸ë ˆì´ë‹ ì„¤ì •\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qa_finetuned_model\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=2,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "# Trainer ìƒì„±\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,  # ì‹¤ì œ keyëŠ” ë°ì´í„° êµ¬ì¡°ì— ë”°ë¼ 'train'ì¼ ìˆ˜ë„ ìˆê³  ì•„ë‹ˆë©´ ê·¸ëƒ¥ [0]ì— ì ‘ê·¼í•´ì•¼ í•  ìˆ˜ë„ ìˆìŒ.\n",
    "    eval_dataset=valid_tokenized,   # ë§ˆì°¬ê°€ì§€ë¡œ ë°ì´í„° êµ¬ì¡° í™•ì¸ í•„ìš”\n",
    "    tokenizer=AutoTokenizer.from_pretrained(\"monologg/koelectra-base-v3-finetuned-korquad\")\n",
    ")\n",
    "\n",
    "# íŒŒì¸íŠœë‹ ì‹¤í–‰\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWB7oRZm_Prc"
   },
   "source": [
    "íŒŒì¸íŠœë‹ í›„ í™•ì¸\n",
    "- íŒŒì¸íŠœë‹ ì¢…ë£Œ í›„ trainer.save_model() í˜¸ì¶œë¡œ ëª¨ë¸ ì €ì¥ ê°€ëŠ¥.\n",
    "- ì €ì¥ëœ ê²½ë¡œë¥¼ ì´ìš©í•´ pipeline(\"question-answering\", model=\"./qa_finetuned_model\") í˜•íƒœë¡œ íŒŒì´í”„ë¼ì¸ ìƒì„± ê°€ëŠ¥."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9j8cmOXV_S_R"
   },
   "source": [
    "íŒŒì¸íŠœë‹ëœ ëª¨ë¸ ë¡œë“œ ë° íŒŒì´í”„ë¼ì¸ ì¬ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1357,
     "status": "ok",
     "timestamp": 1734415859189,
     "user": {
      "displayName": "ê¹€ë¯¼ìˆ˜",
      "userId": "14499279899039145671"
     },
     "user_tz": -540
    },
    "id": "Hp-2EPoM_Uw_",
    "outputId": "4410d9e6-571b-43d6-df69-43fc8aeed7f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë³‘ë ¬ ì²˜ë¦¬ ëŠ¥ë ¥ê³¼ ì¥ê±°ë¦¬ ì˜ì¡´ì„± í¬ì°© ëŠ¥ë ¥ì€\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# íŒŒì¸íŠœë‹ ì™„ë£Œ í›„ ì €ì¥í•œ ëª¨ë¸ ê²½ë¡œ ì‚¬ìš©\n",
    "finetuned_qa_pipeline = pipeline(\"question-answering\", model=\"/content/qa_finetuned_model/checkpoint-290\")\n",
    "\n",
    "result = finetuned_qa_pipeline({\n",
    "    'context': \"\"\"Transformer ëª¨ë¸ì€ ê·¸ í˜ì‹ ì ì¸ êµ¬ì¡°ì™€ ë›°ì–´ë‚œ ì„±ëŠ¥ìœ¼ë¡œ í˜„ëŒ€ NLPì˜ ì¤‘ì‹¬ì´ ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "     ë³‘ë ¬ ì²˜ë¦¬ ëŠ¥ë ¥ê³¼ ì¥ê±°ë¦¬ ì˜ì¡´ì„± í¬ì°© ëŠ¥ë ¥ì€ ì´ì „ ëª¨ë¸ë“¤ì˜ í•œê³„ë¥¼ ê·¹ë³µí–ˆìœ¼ë©°,\n",
    "     ì´ëŠ” ë” í° ëª¨ë¸ê³¼ ë” ë‹¤ì–‘í•œ ì‘ìš©ìœ¼ë¡œ ì´ì–´ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "     ì•ìœ¼ë¡œë„ TransformerëŠ” AI ë°œì „ì˜ í•µì‹¬ ìš”ì†Œë¡œ ê³„ì† ì§„í™”í•  ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.\"\"\",\n",
    "    'question': \"TransformerëŠ” ì´ì „ ëª¨ë¸ì˜ ì–´ë–¤ í•œê³„ë¥¼ ê·¹ë³µí–ˆëŠ”ê°€?\"\n",
    "})\n",
    "\n",
    "print(result['answer'])\n",
    "# íŒŒì¸íŠœë‹ëœ ë°ì´í„°ì…‹ì— ë§ì¶° ê°œì„ ëœ ê²°ê³¼ë¥¼ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "up7wJpl-_ZqQ"
   },
   "source": [
    "### ì •ë¦¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNSmmb9D_V44"
   },
   "source": [
    "- íŒŒì´í”„ë¼ì¸ ëª¨ë¸/í† í¬ë‚˜ì´ì € í™•ì¸: pipeline ê°ì²´ì˜ .model, .tokenizer ì†ì„±ì„ í†µí•´ í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ ì •ë³´ í™•ì¸ ê°€ëŠ¥.\n",
    "- ì›í•˜ëŠ” ëª¨ë¸ ì§€ì •: pipeline ìƒì„± ì‹œ model=\"ëª¨ë¸ì´ë¦„\", tokenizer=\"í† í¬ë‚˜ì´ì €ì´ë¦„\" íŒŒë¼ë¯¸í„°ë¡œ ì„ì˜ì˜ ëª¨ë¸/í† í¬ë‚˜ì´ì € ì§€ì • ê°€ëŠ¥.\n",
    "- íŒŒì¸íŠœë‹: Trainer APIì™€ ë°ì´í„°ì…‹ì„ í™œìš©í•˜ì—¬ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ íŠ¹ì • ë°ì´í„°ì…‹ì— ë§ì¶° ì¬í•™ìŠµí•  ìˆ˜ ìˆìœ¼ë©°, ì™„ë£Œ í›„ í•´ë‹¹ ëª¨ë¸ì„ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ë‹¤ì‹œ ë¡œë“œí•˜ì—¬ ì‚¬ìš© ê°€ëŠ¥.\n",
    "\n",
    "ì´ë¡œì¨, íŒŒì´í”„ë¼ì¸ì˜ ê¸°ë³¸ í™œìš©ë¶€í„° ëª¨ë¸ ì§€ì •, íŒŒì¸íŠœë‹ê¹Œì§€ ì¼ë ¨ì˜ ê³¼ì •ì„ ëª¨ë‘ ì‚´í´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMqeitAipKNoOnCL12TTqT3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
